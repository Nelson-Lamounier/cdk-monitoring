# @format
# @description Reusable Next.js K8s Deployment Workflow (Self-Contained)
#
# Deploys the complete Next.js application via K8s (k3s agent node).
# This pipeline is self-contained â€” it deploys ALL stacks needed for
# the full application to run, not just the K8s compute layer.
#
# Stack Deployment Order:
#   1. Data    (ECR + DynamoDB + S3 + SSM Secrets)
#   2. K8s-Compute (EC2 k3s agent + EIP + S3 manifests)
#   3. API     (API Gateway + Lambda â€” independent of compute path)
#   4. Edge    (CloudFront + ACM + WAF â€” origin = EIP via Traefik)
#
# Post-Deploy:
#   5. Deploy Manifests (via SSM Run Command)
#   6. ArgoCD Sync (best-effort)
#   7. Sync Static Assets (S3 + CloudFront invalidation)
#   8. Verify + Smoke Tests
#
# Parallels _deploy-nextjs.yml (ECS) but replaces Compute/Networking/Application
# stacks with a single K8s-Compute stack + K8s manifest deployment.

name: Deploy Next.js K8s (Reusable)

on:
  workflow_call:
    inputs:
      environment:
        description: "Target environment (development, staging, production)"
        required: true
        type: string
      cdk-environment:
        description: "CDK environment name"
        required: true
        type: string
      require-approval:
        description: "CDK deployment approval mode"
        required: false
        default: "never"
        type: string
      enable-security-scan:
        description: "Run IaC security scan"
        required: false
        default: false
        type: boolean
      security-scan-blocking:
        description: "Fail pipeline on security scan findings"
        required: false
        default: false
        type: boolean
      skip-verification:
        description: "Skip post-deployment verification"
        required: false
        default: false
        type: boolean
      domain-name:
        description: "Domain name for CloudFront Edge stack (optional â€” falls back to vars.DOMAIN_NAME)"
        required: false
        type: string
        default: ""
      hosted-zone-id:
        description: "Route53 Hosted Zone ID (optional â€” falls back to vars.HOSTED_ZONE_ID)"
        required: false
        type: string
        default: ""
      cross-account-role-arn:
        description: "Cross-account IAM role for Route53 (optional â€” falls back to vars.DNS_VALIDATION_ROLE)"
        required: false
        type: string
        default: ""
    secrets:
      AWS_OIDC_ROLE:
        description: "AWS OIDC role ARN"
        required: false
      VERIFICATION_SECRET:
        required: false

env:
  NODE_VERSION: "22"
  AWS_REGION: ${{ vars.AWS_REGION || 'eu-west-1' }}
  DEPLOY_ENVIRONMENT: ${{ inputs.environment }}

jobs:
  # ===========================================================================
  # Setup, Build & Synthesize
  # ===========================================================================
  setup:
    name: Setup & Synthesize
    runs-on: ubuntu-latest
    timeout-minutes: 20
    environment: ${{ inputs.environment }}
    outputs:
      aws-account-id: ${{ steps.account-id.outputs.account_id }}
      commit-sha: ${{ github.sha }}
      commit-short-sha: ${{ steps.commit-info.outputs.short_sha }}
      node-version: ${{ steps.setup-tools.outputs.node-version }}
      # Resolved edge configuration
      domain-name: ${{ steps.resolve-edge.outputs.domain-name }}
      hosted-zone-id: ${{ steps.resolve-edge.outputs.hosted-zone-id }}
      cross-account-role-arn: ${{ steps.resolve-edge.outputs.cross-account-role-arn }}
      # Stack names from synthesize-ci.ts
      data-stack: ${{ steps.synth.outputs.data }}
      k8s-compute-stack: ${{ steps.synth.outputs.k8sCompute }}
      api-stack: ${{ steps.synth.outputs.api }}
      edge-stack: ${{ steps.synth.outputs.edge }}

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Record Commit Information
        id: commit-info
        run: echo "short_sha=${GITHUB_SHA::8}" >> $GITHUB_OUTPUT

      - name: Setup Node.js and Yarn
        id: setup-tools
        uses: ./.github/actions/setup-node-yarn
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Validate AWS Account ID
        id: account-id
        run: |
          ACCOUNT_ID="${{ vars.AWS_ACCOUNT_ID }}"
          if [ -z "$ACCOUNT_ID" ]; then
            echo "ERROR: AWS_ACCOUNT_ID variable not configured"
            exit 1
          fi
          if ! [[ "$ACCOUNT_ID" =~ ^[0-9]{12}$ ]]; then
            echo "ERROR: Invalid AWS account ID format"
            exit 1
          fi
          echo "::add-mask::$ACCOUNT_ID"
          echo "account_id=$ACCOUNT_ID" >> $GITHUB_OUTPUT

      - name: Build TypeScript
        run: yarn build

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722 # v4.1.0
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE }}
          aws-region: ${{ env.AWS_REGION }}
          audience: sts.amazonaws.com

      - name: Resolve Edge Configuration
        id: resolve-edge
        run: |
          DOMAIN="${{ inputs.domain-name }}"
          if [ -z "$DOMAIN" ]; then DOMAIN="${{ vars.DOMAIN_NAME }}"; fi
          if [ -z "$DOMAIN" ]; then
            echo "ERROR: No domain name. Set DOMAIN_NAME in environment '${{ inputs.environment }}'"
            exit 1
          fi

          HZ_ID="${{ inputs.hosted-zone-id }}"
          if [ -z "$HZ_ID" ]; then HZ_ID="${{ vars.HOSTED_ZONE_ID }}"; fi
          if [ -z "$HZ_ID" ]; then
            echo "ERROR: No hosted zone ID. Set HOSTED_ZONE_ID in environment '${{ inputs.environment }}'"
            exit 1
          fi

          ROLE_ARN="${{ inputs.cross-account-role-arn }}"
          if [ -z "$ROLE_ARN" ]; then ROLE_ARN="${{ vars.DNS_VALIDATION_ROLE }}"; fi
          if [ -z "$ROLE_ARN" ]; then
            echo "ERROR: No cross-account role. Set DNS_VALIDATION_ROLE in environment '${{ inputs.environment }}'"
            exit 1
          fi

          echo "domain-name=$DOMAIN" >> $GITHUB_OUTPUT
          echo "hosted-zone-id=$HZ_ID" >> $GITHUB_OUTPUT
          echo "cross-account-role-arn=$ROLE_ARN" >> $GITHUB_OUTPUT
          echo "âœ“ Edge config: $DOMAIN (Zone: $HZ_ID)"

      - name: Synthesize & Determine Stack Names
        id: synth
        env:
          DOMAIN_NAME: ${{ steps.resolve-edge.outputs.domain-name }}
          HOSTED_ZONE_ID: ${{ steps.resolve-edge.outputs.hosted-zone-id }}
          CROSS_ACCOUNT_ROLE_ARN: ${{ steps.resolve-edge.outputs.cross-account-role-arn }}
          NOTIFICATION_EMAIL: ${{ vars.NOTIFICATION_EMAIL }}
          SES_FROM_EMAIL: ${{ vars.SES_FROM_EMAIL }}
          VERIFICATION_SECRET: ${{ secrets.VERIFICATION_SECRET }}
          VERIFICATION_BASE_URL: ${{ vars.VERIFICATION_BASE_URL }}
        run: npx tsx scripts/deployment/synthesize-ci.ts nextjs ${{ inputs.cdk-environment }}

      - name: Get AWS Account ID
        id: account-id-step
        run: echo "account_id=$(aws sts get-caller-identity --query Account --output text)" >> $GITHUB_OUTPUT

      - name: Upload Synthesized Templates
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: cdk-out-nextjs-k8s-${{ inputs.cdk-environment }}-${{ steps.commit-info.outputs.short_sha }}
          path: cdk.out/
          retention-days: 30

      - name: Upload for Security Scan
        if: inputs.enable-security-scan
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: cdk-synthesis
          path: cdk.out/
          retention-days: 7

  # ===========================================================================
  # IaC Security Scan (Conditional)
  # ===========================================================================
  security-scan:
    name: Security Scan
    needs: setup
    if: inputs.enable-security-scan
    uses: ./.github/workflows/_iac-security-scan.yml
    with:
      environment: ${{ inputs.environment }}
      enforce-blocking: ${{ inputs.security-scan-blocking }}
      cdk-output-path: "cdk.out"
      skip-checks: ""
      soft-fail-on: ${{ inputs.security-scan-blocking && '' || 'LOW' }}
    secrets: inherit

  # ===========================================================================
  # Drift Detection
  # ===========================================================================
  drift-detection:
    name: Drift Detection
    needs: [setup]
    runs-on: ubuntu-latest
    timeout-minutes: 15
    environment: ${{ inputs.environment }}
    continue-on-error: true

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Setup Node.js and Yarn
        uses: ./.github/actions/setup-node-yarn
        with:
          node-version: ${{ needs.setup.outputs.node-version }}

      - name: Install Dependencies
        run: yarn install --frozen-lockfile

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722 # v4.1.0
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE }}
          aws-region: ${{ env.AWS_REGION }}
          audience: sts.amazonaws.com

      - name: Run Drift Detection
        run: npx tsx scripts/deployment/drift-detection.ts nextjs ${{ inputs.cdk-environment }} --region ${{ env.AWS_REGION }}
        env:
          AWS_ACCOUNT_ID: ${{ vars.AWS_ACCOUNT_ID }}

  # ===========================================================================
  # Template Validation (cfn-lint)
  # ===========================================================================
  validate-templates:
    name: Validate Templates
    needs: [setup]
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout Config
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          sparse-checkout: .cfnlintrc
          sparse-checkout-cone-mode: false

      - name: Download Synthesized Templates
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        with:
          name: cdk-out-nextjs-k8s-${{ inputs.cdk-environment }}-${{ needs.setup.outputs.commit-short-sha }}
          path: cdk.out/

      - name: Setup Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: "3.11"

      - name: Install cfn-lint
        run: pip install cfn-lint

      - name: Validate CloudFormation Templates
        shell: python3 {0}
        run: |
          import sys, glob
          sys.setrecursionlimit(10000)
          from cfnlint import decode, runner
          from cfnlint.config import ConfigMixIn

          templates = sorted(glob.glob("cdk.out/**/*.template.json", recursive=True))
          print(f"Validating {len(templates)} templates...")
          total_errors = 0
          for tpl in templates:
              print(f"\n--- {tpl} ---")
              try:
                  config = ConfigMixIn(["--template", tpl])
                  matches = list(runner.Runner(config).run())
                  if matches:
                      total_errors += len(matches)
                      for match in matches:
                          print(f"  {match}")
                  else:
                      print("  âœ… passed")
              except RecursionError:
                  print(f"  âš ï¸  skipped (template too deeply nested)")
              except Exception as e:
                  print(f"  âš ï¸  skipped ({type(e).__name__}: {e})")

          if total_errors > 0:
              print(f"\nâŒ {total_errors} validation errors found")
              sys.exit(1)
          else:
              print(f"\nâœ… All {len(templates)} templates passed validation")

  # ===========================================================================
  # Deploy Data Stack (1/4) â€” ECR + DynamoDB + S3 + SSM Secrets
  # ===========================================================================
  deploy-data:
    name: Deploy Data
    needs: [setup, validate-templates, security-scan, drift-detection]
    if: always() && needs.setup.result == 'success' && needs.validate-templates.result == 'success'
    uses: ./.github/workflows/_deploy-stack.yml
    with:
      stack-name: ${{ needs.setup.outputs.data-stack }}
      project: nextjs
      environment: ${{ inputs.environment }}
      aws-account-id: ${{ needs.setup.outputs.aws-account-id }}
      aws-region: ${{ vars.AWS_REGION || 'eu-west-1' }}
      require-approval: ${{ inputs.require-approval }}
      outputs-directory: "deployment-outputs"
    secrets: inherit

  # ===========================================================================
  # Deploy K8s Compute Stack (2/4) â€” EC2 k3s agent + EIP + S3 manifests
  # Replaces: ECS Compute + Networking + Application stacks
  # ===========================================================================
  deploy-k8s-compute:
    name: Deploy K8s Compute
    needs: [setup, deploy-data]
    if: always() && needs.deploy-data.result == 'success'
    uses: ./.github/workflows/_deploy-stack.yml
    with:
      stack-name: ${{ needs.setup.outputs.k8s-compute-stack }}
      project: nextjs
      environment: ${{ inputs.environment }}
      aws-account-id: ${{ needs.setup.outputs.aws-account-id }}
      aws-region: ${{ vars.AWS_REGION || 'eu-west-1' }}
      require-approval: ${{ inputs.require-approval }}
      outputs-directory: "deployment-outputs"
    secrets: inherit

  # ===========================================================================
  # Deploy API Stack (3/4) â€” API Gateway + Lambda (independent lifecycle)
  # ===========================================================================
  deploy-api:
    name: Deploy API
    needs: [setup, deploy-data]
    if: always() && needs.deploy-data.result == 'success'
    uses: ./.github/workflows/_deploy-stack.yml
    with:
      stack-name: ${{ needs.setup.outputs.api-stack }}
      project: nextjs
      environment: ${{ inputs.environment }}
      aws-account-id: ${{ needs.setup.outputs.aws-account-id }}
      aws-region: ${{ vars.AWS_REGION || 'eu-west-1' }}
      require-approval: ${{ inputs.require-approval }}
      outputs-directory: "deployment-outputs"
      notification-email: ${{ vars.NOTIFICATION_EMAIL }}
      ses-from-email: ${{ vars.SES_FROM_EMAIL }}
      verification-base-url: ${{ vars.VERIFICATION_BASE_URL }}
    secrets: inherit

  # ===========================================================================
  # Deploy Edge Stack (4/4) â€” CloudFront + ACM + WAF (us-east-1)
  # Origin: Elastic IP (via Traefik) â€” replaces ALB origin from ECS path
  # ===========================================================================
  deploy-edge:
    name: Deploy Edge
    needs: [setup, deploy-k8s-compute, deploy-api]
    if: always() && needs.deploy-k8s-compute.result == 'success' && needs.deploy-api.result == 'success'
    uses: ./.github/workflows/_deploy-stack.yml
    with:
      stack-name: ${{ needs.setup.outputs.edge-stack }}
      project: nextjs
      environment: ${{ inputs.environment }}
      aws-account-id: ${{ needs.setup.outputs.aws-account-id }}
      aws-region: ${{ vars.ROUTE53_REGION || 'us-east-1' }}
      require-approval: ${{ inputs.require-approval }}
      outputs-directory: "deployment-outputs"
      domain-name: ${{ needs.setup.outputs.domain-name }}
      hosted-zone-id: ${{ needs.setup.outputs.hosted-zone-id }}
      cross-account-role-arn: ${{ needs.setup.outputs.cross-account-role-arn }}
    secrets: inherit

  # ===========================================================================
  # Deploy K8s Manifests via SSM Run Command
  # ===========================================================================
  deploy-manifests:
    name: Deploy Manifests
    needs: [setup, deploy-k8s-compute]
    if: always() && needs.deploy-k8s-compute.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 15
    environment: ${{ inputs.environment }}

    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722 # v4.1.0
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE }}
          aws-region: ${{ env.AWS_REGION }}
          audience: sts.amazonaws.com

      - name: Get Instance ID
        id: instance
        run: |
          SSM_PREFIX="/nextjs-k8s/${{ inputs.environment }}"
          INSTANCE_ID=$(aws ssm get-parameter \
            --name "${SSM_PREFIX}/agent-instance-id" \
            --query "Parameter.Value" \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")

          if [ -z "${INSTANCE_ID}" ]; then
            echo "::warning::No agent instance-id found â€” skipping manifest deployment"
            echo "skip=true" >> $GITHUB_OUTPUT
          else
            echo "instance_id=${INSTANCE_ID}" >> $GITHUB_OUTPUT
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "Instance: ${INSTANCE_ID}"
          fi

      - name: Wait for SSM Agent
        if: steps.instance.outputs.skip != 'true'
        run: |
          INSTANCE_ID="${{ steps.instance.outputs.instance_id }}"
          echo "Waiting for SSM Agent on ${INSTANCE_ID}..."
          MAX_WAIT=120
          WAITED=0
          while true; do
            STATUS=$(aws ssm describe-instance-information \
              --filters "Key=InstanceIds,Values=${INSTANCE_ID}" \
              --query "InstanceInformationList[0].PingStatus" \
              --output text \
              --region ${{ env.AWS_REGION }} 2>/dev/null || echo "NotFound")
            if [ "$STATUS" = "Online" ]; then
              echo "âœ“ SSM Agent online (waited ${WAITED}s)"
              break
            fi
            if [ $WAITED -ge $MAX_WAIT ]; then
              echo "::error::SSM Agent not online after ${MAX_WAIT}s"
              exit 1
            fi
            sleep 5
            WAITED=$((WAITED + 5))
          done

      - name: Deploy Manifests via SSM
        if: steps.instance.outputs.skip != 'true'
        id: deploy
        run: |
          INSTANCE_ID="${{ steps.instance.outputs.instance_id }}"
          DOC_NAME="${{ inputs.environment == 'production' && 'nextjs-k8s-production-k8s' || 'nextjs-k8s-development-k8s' }}-deploy-manifests"

          echo "Sending SSM command: ${DOC_NAME} â†’ ${INSTANCE_ID}"
          COMMAND_ID=$(aws ssm send-command \
            --document-name "${DOC_NAME}" \
            --targets "Key=instanceids,Values=${INSTANCE_ID}" \
            --timeout-seconds 600 \
            --query "Command.CommandId" \
            --output text \
            --region ${{ env.AWS_REGION }})

          echo "command_id=${COMMAND_ID}" >> $GITHUB_OUTPUT
          echo "SSM Command: ${COMMAND_ID}"

          # Poll for completion with progress indicators
          WAITED=0
          LAST_OUTPUT_LEN=0
          while true; do
            CMD_STATUS=$(aws ssm get-command-invocation \
              --command-id "${COMMAND_ID}" \
              --instance-id "${INSTANCE_ID}" \
              --query "Status" \
              --output text \
              --region ${{ env.AWS_REGION }} 2>/dev/null || echo "InProgress")

            if [ "$CMD_STATUS" = "Success" ]; then
              echo "âœ“ Manifest deployment completed successfully"
              break
            elif [ "$CMD_STATUS" = "Failed" ] || [ "$CMD_STATUS" = "Cancelled" ] || [ "$CMD_STATUS" = "TimedOut" ]; then
              echo "::error::SSM command ${CMD_STATUS}"

              # Capture both stdout and stderr on failure
              echo "--- SSM Command Output (stdout) ---"
              aws ssm get-command-invocation \
                --command-id "${COMMAND_ID}" \
                --instance-id "${INSTANCE_ID}" \
                --query "StandardOutputContent" \
                --output text \
                --region ${{ env.AWS_REGION }} 2>/dev/null || echo "(stdout unavailable)"

              echo "--- SSM Command Output (stderr) ---"
              aws ssm get-command-invocation \
                --command-id "${COMMAND_ID}" \
                --instance-id "${INSTANCE_ID}" \
                --query "StandardErrorContent" \
                --output text \
                --region ${{ env.AWS_REGION }} 2>/dev/null || echo "(stderr unavailable)"

              exit 1
            fi

            if [ $WAITED -ge 600 ]; then
              echo "::error::SSM command timed out after 600s"
              exit 1
            fi

            sleep 10
            WAITED=$((WAITED + 10))
            echo "  â³ Status: ${CMD_STATUS} (${WAITED}s / 600s)"
          done

      - name: Trigger ArgoCD Sync
        if: steps.instance.outputs.skip != 'true'
        continue-on-error: true
        run: |
          INSTANCE_ID="${{ steps.instance.outputs.instance_id }}"
          echo "Triggering ArgoCD sync for nextjs app..."

          COMMAND_ID=$(aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --targets "Key=instanceids,Values=${INSTANCE_ID}" \
            --parameters 'commands=["if command -v argocd &>/dev/null; then argocd app sync nextjs --grpc-web 2>/dev/null || echo \"ArgoCD sync skipped (not configured)\"; else echo \"ArgoCD not installed â€” skipping sync\"; fi"]' \
            --timeout-seconds 60 \
            --query "Command.CommandId" \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")

          if [ -n "${COMMAND_ID}" ]; then
            echo "ArgoCD sync triggered: ${COMMAND_ID}"
          else
            echo "ArgoCD sync skipped"
          fi

      - name: Collect Deployment Logs
        if: steps.instance.outputs.skip != 'true' && always()
        run: |
          COMMAND_ID="${{ steps.deploy.outputs.command_id }}"
          INSTANCE_ID="${{ steps.instance.outputs.instance_id }}"

          if [ -n "${COMMAND_ID}" ]; then
            # Capture stdout
            echo "### ðŸ“‹ Manifest Deployment â€” stdout" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            aws ssm get-command-invocation \
              --command-id "${COMMAND_ID}" \
              --instance-id "${INSTANCE_ID}" \
              --query "StandardOutputContent" \
              --output text \
              --region ${{ env.AWS_REGION }} 2>/dev/null >> $GITHUB_STEP_SUMMARY || echo "(stdout unavailable)"
            echo '```' >> $GITHUB_STEP_SUMMARY

            # Capture stderr (often contains kubectl warnings, AWS CLI errors)
            STDERR=$(aws ssm get-command-invocation \
              --command-id "${COMMAND_ID}" \
              --instance-id "${INSTANCE_ID}" \
              --query "StandardErrorContent" \
              --output text \
              --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
            if [ -n "${STDERR}" ] && [ "${STDERR}" != "None" ]; then
              echo "### âš ï¸ Manifest Deployment â€” stderr" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "${STDERR}" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
            fi

            # Show execution status metadata
            echo "### ðŸ“Š SSM Command Metadata" >> $GITHUB_STEP_SUMMARY
            echo '```json' >> $GITHUB_STEP_SUMMARY
            aws ssm get-command-invocation \
              --command-id "${COMMAND_ID}" \
              --instance-id "${INSTANCE_ID}" \
              --query '{Status: Status, StatusDetails: StatusDetails, ExecutionStartDateTime: ExecutionStartDateTime, ExecutionEndDateTime: ExecutionEndDateTime, ResponseCode: ResponseCode}' \
              --output json \
              --region ${{ env.AWS_REGION }} 2>/dev/null >> $GITHUB_STEP_SUMMARY || echo "{}"
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

      - name: Diagnose Failed Pods
        if: steps.instance.outputs.skip != 'true' && failure()
        continue-on-error: true
        run: |
          INSTANCE_ID="${{ steps.instance.outputs.instance_id }}"
          echo "::group::ðŸ” Pod Failure Diagnostics"
          echo "Gathering diagnostics from instance ${INSTANCE_ID}..."

          DIAG_COMMAND_ID=$(aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --targets "Key=instanceids,Values=${INSTANCE_ID}" \
            --parameters 'commands=[
              "export KUBECONFIG=/data/k3s/server/cred/admin.kubeconfig",
              "echo \"=== Node Status ===",
              "kubectl get nodes -o wide 2>/dev/null || echo \"kubectl not available\"",
              "echo \"\"",
              "echo \"=== All Pods ===",
              "kubectl get pods -A -o wide 2>/dev/null || echo \"No pods found\"",
              "echo \"\"",
              "echo \"=== Non-Running Pods (describe) ===",
              "for ns_pod in $(kubectl get pods -A --field-selector=status.phase!=Running,status.phase!=Succeeded --no-headers -o custom-columns=NS:.metadata.namespace,NAME:.metadata.name 2>/dev/null | tr \"\\t\" \"/\"); do ns=${ns_pod%%/*}; pod=${ns_pod##*/}; echo \"--- $ns/$pod ---\"; kubectl describe pod $pod -n $ns 2>/dev/null | tail -30; echo \"\"; done",
              "echo \"=== Recent Events (last 30) ===",
              "kubectl get events -A --sort-by=.lastTimestamp 2>/dev/null | tail -30",
              "echo \"\"",
              "echo \"=== k3s Service Status ===",
              "systemctl is-active k3s && echo \"k3s: active\" || echo \"k3s: INACTIVE\"",
              "echo \"=== System Resources ===",
              "free -h",
              "df -h /data"
            ]' \
            --timeout-seconds 60 \
            --query "Command.CommandId" \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")

          if [ -n "${DIAG_COMMAND_ID}" ]; then
            # Wait for diagnostics to complete
            sleep 20

            echo "### ðŸ” Pod Failure Diagnostics" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            aws ssm get-command-invocation \
              --command-id "${DIAG_COMMAND_ID}" \
              --instance-id "${INSTANCE_ID}" \
              --query "StandardOutputContent" \
              --output text \
              --region ${{ env.AWS_REGION }} 2>/dev/null >> $GITHUB_STEP_SUMMARY || echo "Diagnostics unavailable"
            echo '```' >> $GITHUB_STEP_SUMMARY

            # Also print to console for immediate visibility
            aws ssm get-command-invocation \
              --command-id "${DIAG_COMMAND_ID}" \
              --instance-id "${INSTANCE_ID}" \
              --query "StandardOutputContent" \
              --output text \
              --region ${{ env.AWS_REGION }} 2>/dev/null || echo "Diagnostics unavailable"
          else
            echo "::warning::Could not send diagnostics command to instance"
          fi
          echo "::endgroup::"

  # ===========================================================================
  # Verify Service (K8s-specific: checks EIP health + pod readiness)
  # ===========================================================================
  verify-service:
    name: Verify Service
    needs: [setup, deploy-k8s-compute, deploy-manifests]
    runs-on: ubuntu-latest
    timeout-minutes: 15
    environment: ${{ inputs.environment }}
    if: always() && needs.deploy-k8s-compute.result == 'success' && inputs.skip-verification != true

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Setup Node.js and Yarn
        uses: ./.github/actions/setup-node-yarn
        with:
          node-version: ${{ needs.setup.outputs.node-version }}

      - name: Install Dependencies
        run: yarn install --frozen-lockfile

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722 # v4.1.0
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE }}
          aws-region: ${{ env.AWS_REGION }}
          audience: sts.amazonaws.com

      - name: Verify K8s Stack
        uses: ./.github/workflows/_verify-stack.yml
        with:
          stack-name: ${{ needs.setup.outputs.k8s-compute-stack }}
          environment: ${{ inputs.environment }}
          aws-region: ${{ vars.AWS_REGION || 'eu-west-1' }}

  # ===========================================================================
  # Sync Static Assets to S3 + CloudFront Cache Invalidation
  # ===========================================================================
  sync-static-assets:
    name: Sync Static Assets
    needs: [setup, deploy-data, deploy-edge]
    runs-on: ubuntu-latest
    timeout-minutes: 10
    environment: ${{ inputs.environment }}
    if: always() && needs.deploy-data.result == 'success' && (needs.deploy-edge.result == 'success' || needs.deploy-edge.result == 'skipped')
    outputs:
      s3-bucket: ${{ steps.sync.outputs.bucket }}
      files-synced: ${{ steps.sync.outputs.files_synced }}
      invalidation-id: ${{ steps.sync.outputs.invalidation_id }}

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Setup Node.js and Yarn
        uses: ./.github/actions/setup-node-yarn
        with:
          node-version: ${{ needs.setup.outputs.node-version }}

      - name: Install Dependencies
        run: yarn install --frozen-lockfile

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722 # v4.1.0
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE }}
          aws-region: ${{ env.AWS_REGION }}
          audience: sts.amazonaws.com

      - name: Download Build Artifacts
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        with:
          name: cdk-out-nextjs-k8s-${{ inputs.cdk-environment }}-${{ needs.setup.outputs.commit-short-sha }}
          path: cdk.out/

      - name: Sync Assets & Invalidate Cache
        id: sync
        run: |
          SYNC_CMD="npx tsx scripts/deployment/sync-assets-ci.ts ${{ inputs.cdk-environment }}"
          SYNC_CMD="$SYNC_CMD --region ${{ env.AWS_REGION }}"

          if [ -n "${{ needs.setup.outputs.domain-name }}" ]; then
            SYNC_CMD="$SYNC_CMD --domain ${{ needs.setup.outputs.domain-name }}"
          fi

          eval $SYNC_CMD

  # ===========================================================================
  # Smoke Tests
  # ===========================================================================
  smoke-tests:
    name: Smoke Tests
    needs:
      [
        setup,
        deploy-k8s-compute,
        deploy-manifests,
        verify-service,
        sync-static-assets,
      ]
    if: >-
      always()
      && needs.deploy-k8s-compute.result == 'success'
      && (needs.verify-service.result == 'success' || needs.verify-service.result == 'skipped')
      && inputs.skip-verification != true
    uses: ./.github/workflows/_smoke-tests-nextjs.yml
    with:
      environment: ${{ inputs.environment }}
      aws-account-id: ${{ needs.setup.outputs.aws-account-id }}
      aws-region: ${{ vars.AWS_REGION || 'eu-west-1' }}
      cloudfront-domain: ${{ needs.setup.outputs.domain-name }}
      s3-assets-bucket: ${{ needs.sync-static-assets.outputs.s3-bucket }}
      timeout-minutes: 10
    secrets: inherit

  # ===========================================================================
  # Rollback (Conditional â€” staging/production only)
  #
  # Triggers when K8s Compute deployed successfully but verification failed.
  # Rolls back CloudFormation to the previous known-good template.
  # ===========================================================================
  rollback:
    name: Rollback K8s Compute
    needs: [setup, deploy-k8s-compute, deploy-manifests, verify-service]
    runs-on: ubuntu-latest
    timeout-minutes: 20
    environment: ${{ inputs.environment }}
    if: |
      always()
      && needs.deploy-k8s-compute.result == 'success'
      && needs.verify-service.result == 'failure'
      && inputs.cdk-environment != 'development'

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Setup Node.js and Yarn
        uses: ./.github/actions/setup-node-yarn
        with:
          node-version: ${{ needs.setup.outputs.node-version }}

      - name: Install Dependencies
        run: yarn install --frozen-lockfile

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722 # v4.1.0
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE }}
          aws-region: ${{ env.AWS_REGION }}
          audience: sts.amazonaws.com

      - name: Rollback K8s Compute Stack
        id: rollback
        run: npx tsx scripts/deployment/rollback.ts "${{ needs.setup.outputs.k8s-compute-stack }}" --region ${{ env.AWS_REGION }}

  # ===========================================================================
  # Deployment Summary
  # ===========================================================================
  summary:
    name: Deployment Summary
    needs:
      - setup
      - security-scan
      - drift-detection
      - deploy-data
      - deploy-k8s-compute
      - deploy-api
      - deploy-edge
      - deploy-manifests
      - sync-static-assets
      - verify-service
      - smoke-tests
      - rollback
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: always()

    steps:
      - name: Check Prerequisites
        id: prereqs
        run: |
          if [ "${{ needs.setup.result }}" != "success" ]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## âš ï¸ Pipeline Aborted

          **Reason**: Setup job did not complete successfully (`${{ needs.setup.result }}`)
          **Commit**: `${{ github.sha }}`
          **Environment**: ${{ inputs.environment }}

          No stacks were deployed. Check the setup job logs for details.
          EOF
            echo "::warning::Setup did not succeed (${{ needs.setup.result }})"
          else
            echo "skip=false" >> $GITHUB_OUTPUT
          fi

      - name: Generate Summary
        if: steps.prereqs.outputs.skip != 'true'
        run: |
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## Next.js K8s Deployment Summary

          | Stack / Step | Result |
          |---|---|
          | Setup & Synthesize | âœ… ${{ needs.setup.result }} |
          | Security Scan | ${{ needs.security-scan.result || 'skipped' }} |
          | Drift Detection | ${{ needs.drift-detection.result || 'skipped' }} |
          | **Deploy Data** | ${{ needs.deploy-data.result || 'skipped' }} |
          | **Deploy K8s Compute** | ${{ needs.deploy-k8s-compute.result || 'skipped' }} |
          | **Deploy API** | ${{ needs.deploy-api.result || 'skipped' }} |
          | **Deploy Edge** | ${{ needs.deploy-edge.result || 'skipped' }} |
          | Deploy Manifests | ${{ needs.deploy-manifests.result || 'skipped' }} |
          | Sync Static Assets | ${{ needs.sync-static-assets.result || 'skipped' }} |
          | Verify Service | ${{ needs.verify-service.result || 'skipped' }} |
          | Smoke Tests | ${{ needs.smoke-tests.result || 'skipped' }} |
          | Rollback | ${{ needs.rollback.result || 'skipped' }} |

          **Environment**: ${{ inputs.environment }}
          **Commit**: \`${{ needs.setup.outputs.commit-short-sha }}\`
          **Triggered by**: ${{ github.event_name }} (${{ github.actor }})

          ### Stack Deployment Order
          \`\`\`
          Data â†’ K8s-Compute â”€â”€â†’ Deploy Manifests â†’ ArgoCD Sync
               â†˜ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Edge â†’ Sync Assets â†’ Smoke Tests
          \`\`\`
          EOF
