# @format
# @description Reusable K8s Content Sync Workflow
#
# Syncs a local directory (k8s-bootstrap or app-deploy) to the S3 scripts bucket
# created by the Infra pipeline. Discovers the bucket via SSM parameter.
#
# After sync, creates/updates an SSM State Manager association for continuous
# configuration enforcement. The association re-applies the SSM document on schedule.
#
# Prerequisites:
#   - Infra pipeline has run at least once (SSM parameter exists) - Test

name: Sync K8s Content (Reusable)

on:
  workflow_call:
    inputs:
      environment:
        description: "Target environment (development, staging, production)"
        required: true
        type: string
      cdk-environment:
        description: "CDK context environment value"
        required: true
        type: string
      content-type:
        description: "Content type label for logging (bootstrap | app)"
        required: true
        type: string
      source-dir:
        description: "Local directory to sync (e.g., ./k8s-bootstrap)"
        required: true
        type: string
      s3-prefix:
        description: "S3 key prefix (e.g., k8s-bootstrap or app-deploy)"
        required: true
        type: string
      ssm-document:
        description: "SSM document name for State Manager association (optional)"
        required: false
        type: string
        default: ""
      association-name:
        description: "Unique name for the SSM State Manager association"
        required: false
        type: string
        default: ""
      schedule-expression:
        description: "State Manager schedule (rate or cron expression)"
        required: false
        type: string
        default: "rate(30 minutes)"
    secrets:
      AWS_OIDC_ROLE:
        description: "AWS OIDC role ARN"
        required: false

env:
  AWS_REGION: ${{ vars.AWS_REGION || 'eu-west-1' }}

jobs:
  sync:
    name: "Sync ${{ inputs.content-type }}"
    runs-on: ubuntu-latest
    timeout-minutes: 10
    environment: ${{ inputs.environment }}

    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722 # v4.1.0
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE }}
          aws-region: ${{ env.AWS_REGION }}
          audience: sts.amazonaws.com

      # -----------------------------------------------------------------------
      # 1. Discover the S3 bucket from SSM (written by Infra pipeline)
      # -----------------------------------------------------------------------
      - name: Discover Scripts Bucket
        id: bucket
        run: |
          SSM_KEY="/k8s/${{ inputs.cdk-environment }}/scripts-bucket"
          echo "Looking up SSM parameter: ${SSM_KEY}"

          BUCKET=$(aws ssm get-parameter \
            --name "${SSM_KEY}" \
            --query 'Parameter.Value' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")

          if [ -z "$BUCKET" ]; then
            echo "::error::SSM parameter ${SSM_KEY} not found. Has the Infra pipeline been deployed?"
            exit 1
          fi

          # Normalize — strip any s3:// prefix or trailing slashes
          BUCKET=$(echo "$BUCKET" | sed 's|^s3://||' | sed 's|/$||')
          echo "bucket=${BUCKET}" >> $GITHUB_OUTPUT
          echo "✓ Scripts bucket: ${BUCKET}"

      # -----------------------------------------------------------------------
      # 2. Sync content to S3
      # -----------------------------------------------------------------------
      - name: "Sync ${{ inputs.content-type }} to S3"
        run: |
          SOURCE="${{ inputs.source-dir }}"
          DEST="s3://${{ steps.bucket.outputs.bucket }}/${{ inputs.s3-prefix }}/"

          echo "Syncing: ${SOURCE} → ${DEST}"
          aws s3 sync "${SOURCE}" "${DEST}" --delete --region ${{ env.AWS_REGION }}
          echo "✓ Sync complete"

      # -----------------------------------------------------------------------
      # 3. Create/Update SSM State Manager Association (continuous config)
      # -----------------------------------------------------------------------
      - name: Ensure SSM State Manager Association
        if: inputs.ssm-document != '' && inputs.association-name != ''
        run: |
          SSM_PREFIX="/k8s/${{ inputs.cdk-environment }}"
          ASSOC_NAME="${{ inputs.association-name }}"
          DOC_NAME="${{ inputs.ssm-document }}"
          SCHEDULE="${{ inputs.schedule-expression }}"
          BUCKET="${{ steps.bucket.outputs.bucket }}"
          REGION="${{ env.AWS_REGION }}"

          # Look up instance ID to verify infra exists
          INSTANCE_ID=$(aws ssm get-parameter \
            --name "${SSM_PREFIX}/instance-id" \
            --query 'Parameter.Value' --output text \
            --region "${REGION}" 2>/dev/null || echo "")

          if [ -z "$INSTANCE_ID" ]; then
            echo "::warning::No instance ID in SSM — skipping association (Day-0 bootstrap?)"
            exit 0
          fi

          # Common parameters for the SSM document
          PARAMS="S3Bucket=[${BUCKET}],S3KeyPrefix=[${{ inputs.s3-prefix }}],Region=[${REGION}],SsmPrefix=[${SSM_PREFIX}]"

          echo "Creating/updating State Manager association: ${ASSOC_NAME}"
          echo "  Document:  ${DOC_NAME}"
          echo "  Target:    ${INSTANCE_ID}"
          echo "  Schedule:  ${SCHEDULE}"

          # Try create first; capture stderr to diagnose failures
          CREATE_ERR=$(mktemp)
          if aws ssm create-association \
            --association-name "${ASSOC_NAME}" \
            --name "${DOC_NAME}" \
            --targets "Key=InstanceIds,Values=${INSTANCE_ID}" \
            --parameters "${PARAMS}" \
            --schedule-expression "${SCHEDULE}" \
            --region "${REGION}" 2>"${CREATE_ERR}"; then
            echo "✓ Association created: ${ASSOC_NAME}"
          else
            CREATE_MSG=$(cat "${CREATE_ERR}")
            echo "Create failed: ${CREATE_MSG}"

            # Look up existing association by name using list-associations
            # (describe-association requires --association-id or --name+--instance-id,
            #  --association-name alone is not sufficient for lookup)
            echo "Looking up existing association: ${ASSOC_NAME}..."
            ASSOC_ID=$(aws ssm list-associations \
              --association-filter-list "key=AssociationName,value=${ASSOC_NAME}" \
              --query 'Associations[0].AssociationId' \
              --output text \
              --region "${REGION}" 2>/dev/null || echo "")

            # list-associations returns "None" when no results
            if [ -z "$ASSOC_ID" ] || [ "$ASSOC_ID" = "None" ]; then
              echo "::error::Could not find or create association ${ASSOC_NAME}"
              echo "::error::Create error was: ${CREATE_MSG}"
              exit 1
            fi

            echo "Found association: ${ASSOC_ID} — updating..."
            aws ssm update-association \
              --association-id "${ASSOC_ID}" \
              --name "${DOC_NAME}" \
              --targets "Key=InstanceIds,Values=${INSTANCE_ID}" \
              --parameters "${PARAMS}" \
              --schedule-expression "${SCHEDULE}" \
              --region "${REGION}"
            echo "✓ Association updated: ${ASSOC_NAME} (${ASSOC_ID})"
          fi
          rm -f "${CREATE_ERR}"

      # -----------------------------------------------------------------------
      # 4. Apply association immediately (one-shot after sync)
      # -----------------------------------------------------------------------
      - name: Apply Association Now
        if: inputs.ssm-document != '' && inputs.association-name != ''
        run: |
          ASSOC_NAME="${{ inputs.association-name }}"
          REGION="${{ env.AWS_REGION }}"

          ASSOC_ID=$(aws ssm list-associations \
            --association-filter-list "key=AssociationName,value=${ASSOC_NAME}" \
            --query 'Associations[0].AssociationId' \
            --output text \
            --region "${REGION}" 2>/dev/null || echo "")

          if [ -z "$ASSOC_ID" ] || [ "$ASSOC_ID" = "None" ]; then
            echo "::warning::Association ${ASSOC_NAME} not found — skipping immediate apply"
            exit 0
          fi

          echo "Triggering immediate apply: ${ASSOC_NAME} (${ASSOC_ID})"
          aws ssm start-associations-once \
            --association-ids "${ASSOC_ID}" \
            --region "${REGION}" 2>/dev/null || true
          echo "✓ Association apply triggered"

      # -----------------------------------------------------------------------
      # 5. Wait for association execution to complete
      #
      # Polls the association status to verify the deploy script ran
      # successfully on the instance. Both bootstrap and app-deploy
      # associations are idempotent, so ordering between them is not
      # enforced — each deploy script handles missing dependencies
      # gracefully and SSM re-runs every 30 minutes for convergence.
      # -----------------------------------------------------------------------
      - name: Wait for Execution
        if: inputs.ssm-document != '' && inputs.association-name != ''
        run: |
          ASSOC_NAME="${{ inputs.association-name }}"
          REGION="${{ env.AWS_REGION }}"
          TIMEOUT=300  # 5 minutes
          POLL_INTERVAL=15
          ELAPSED=0

          ASSOC_ID=$(aws ssm list-associations \
            --association-filter-list "key=AssociationName,value=${ASSOC_NAME}" \
            --query 'Associations[0].AssociationId' \
            --output text \
            --region "${REGION}" 2>/dev/null || echo "")

          if [ -z "$ASSOC_ID" ] || [ "$ASSOC_ID" = "None" ]; then
            echo "::warning::Association not found — skipping health check"
            exit 0
          fi

          echo "Waiting for association ${ASSOC_NAME} execution (timeout: ${TIMEOUT}s)..."

          while [ $ELAPSED -lt $TIMEOUT ]; do
            STATUS=$(aws ssm describe-association-executions \
              --association-id "${ASSOC_ID}" \
              --max-results 1 \
              --query 'AssociationExecutions[0].Status' \
              --output text \
              --region "${REGION}" 2>/dev/null || echo "Unknown")

            case "$STATUS" in
              Success)
                echo "✓ Association execution completed successfully"
                exit 0
                ;;
              Failed)
                echo "::warning::Association execution failed — check SSM Run Command history"
                echo "::warning::Deploy scripts are idempotent; next SSM schedule (30min) or ArgoCD will retry"
                exit 0  # Non-blocking: don't fail the pipeline
                ;;
              TimedOut)
                echo "::warning::Association execution timed out on the instance"
                exit 0
                ;;
            esac

            sleep $POLL_INTERVAL
            ELAPSED=$((ELAPSED + POLL_INTERVAL))
            echo "  Status: ${STATUS} (${ELAPSED}s / ${TIMEOUT}s)"
          done

          echo "::warning::Health check timed out after ${TIMEOUT}s — execution may still be in progress"

      # -----------------------------------------------------------------------
      # 6. ArgoCD Health Check (bootstrap syncs only)
      #
      # After the bootstrap association completes, queries the K8s node
      # via SSM Run Command to check ArgoCD status. Shows:
      #   - ArgoCD pods (running/crashloop)
      #   - Application sync + health status
      #   - Recent ArgoCD events
      #
      # Non-blocking: failures emit warnings but don't break the pipeline.
      # -----------------------------------------------------------------------
      - name: ArgoCD Health Check
        if: inputs.content-type == 'bootstrap' && inputs.ssm-document != ''
        run: |
          REGION="${{ env.AWS_REGION }}"
          SSM_PREFIX="/k8s/${{ inputs.cdk-environment }}"

          INSTANCE_ID=$(aws ssm get-parameter \
            --name "${SSM_PREFIX}/instance-id" \
            --query 'Parameter.Value' --output text \
            --region "${REGION}" 2>/dev/null || echo "")

          if [ -z "$INSTANCE_ID" ]; then
            echo "::warning::No instance ID — skipping ArgoCD check"
            exit 0
          fi

          echo "============================================="
          echo "  ArgoCD Health Check (via SSM Run Command)  "
          echo "============================================="
          echo ""

          # Send a command to the node to check ArgoCD status
          CMD_ID=$(aws ssm send-command \
            --instance-ids "${INSTANCE_ID}" \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=[
              "export KUBECONFIG=/etc/kubernetes/admin.conf",
              "echo \"--- ArgoCD Pods ---\"",
              "kubectl get pods -n argocd -o wide 2>/dev/null || echo \"ArgoCD namespace not found\"",
              "echo \"\"",
              "echo \"--- ArgoCD Applications ---\"",
              "kubectl get applications -n argocd -o custom-columns=NAME:.metadata.name,SYNC:.status.sync.status,HEALTH:.status.health.status,REPO:.spec.source.repoURL,PATH:.spec.source.path 2>/dev/null || echo \"No ArgoCD Applications found\"",
              "echo \"\"",
              "echo \"--- ArgoCD Repo Server Logs (last 10 lines) ---\"",
              "kubectl logs -n argocd -l app.kubernetes.io/name=argocd-repo-server --tail=10 2>/dev/null || echo \"No repo-server logs\"",
              "echo \"\"",
              "echo \"--- Recent ArgoCD Events ---\"",
              "kubectl get events -n argocd --sort-by=.lastTimestamp --field-selector type!=Normal 2>/dev/null | tail -15 || echo \"No warning events\""
            ]' \
            --timeout-seconds 60 \
            --query 'Command.CommandId' \
            --output text \
            --region "${REGION}" 2>/dev/null || echo "")

          if [ -z "$CMD_ID" ]; then
            echo "::warning::Failed to send SSM command — IAM permissions may be missing"
            exit 0
          fi

          echo "SSM Command ID: $CMD_ID"
          echo "Waiting for output..."
          echo ""

          # Wait for the command to complete (up to 90 seconds)
          TIMEOUT=90
          ELAPSED=0
          while [ $ELAPSED -lt $TIMEOUT ]; do
            sleep 5
            ELAPSED=$((ELAPSED + 5))

            STATUS=$(aws ssm get-command-invocation \
              --command-id "$CMD_ID" \
              --instance-id "${INSTANCE_ID}" \
              --query 'Status' \
              --output text \
              --region "${REGION}" 2>/dev/null || echo "Pending")

            case "$STATUS" in
              Success)
                # Fetch and display the output
                aws ssm get-command-invocation \
                  --command-id "$CMD_ID" \
                  --instance-id "${INSTANCE_ID}" \
                  --query 'StandardOutputContent' \
                  --output text \
                  --region "${REGION}" 2>/dev/null || echo "(No output)"

                STDERR=$(aws ssm get-command-invocation \
                  --command-id "$CMD_ID" \
                  --instance-id "${INSTANCE_ID}" \
                  --query 'StandardErrorContent' \
                  --output text \
                  --region "${REGION}" 2>/dev/null || echo "")
                if [ -n "$STDERR" ] && [ "$STDERR" != "None" ]; then
                  echo ""
                  echo "--- Errors ---"
                  echo "$STDERR"
                fi
                echo ""
                echo "✓ ArgoCD health check complete"
                exit 0
                ;;
              Failed|TimedOut|Cancelled)
                echo "::warning::ArgoCD health check command ${STATUS}"
                # Still try to fetch partial output
                aws ssm get-command-invocation \
                  --command-id "$CMD_ID" \
                  --instance-id "${INSTANCE_ID}" \
                  --query 'StandardOutputContent' \
                  --output text \
                  --region "${REGION}" 2>/dev/null || true
                exit 0
                ;;
            esac
          done

          echo "::warning::ArgoCD health check timed out after ${TIMEOUT}s"
