/**
 * @format
 * AI Publisher — Lambda Handler
 *
 * Implements the "Sync-and-Transform" pattern with the Metadata Brain model:
 *   S3 event (drafts/*.md) → Read .md → Converse API (Claude 4.6)
 *     → Write .mdx to S3 (published/ + content/v{n}/)
 *     → Write AI-enhanced metadata to DynamoDB
 *
 * DynamoDB Entity Schema (Metadata Brain):
 *   pk: ARTICLE#<slug>
 *   sk: METADATA        — latest AI-enhanced metadata + s3Key pointer
 *   sk: CONTENT#v<ts>   — versioned S3 content pointer
 *
 * Content blobs live in S3 at content/v{n}/<slug>.mdx, bypassing
 * the 400KB DynamoDB item limit.
 *
 * Features:
 * - Bedrock Converse API with Prompt Caching
 * - Adaptive Thinking with dynamic budget based on content complexity
 * - AI-enhanced metadata (aiSummary, readingTime, technicalConfidence)
 * - Content versioning in S3
 */

import type { S3Event, S3Handler } from 'aws-lambda';

import {
    BedrockRuntimeClient,
    ConverseCommand,
} from '@aws-sdk/client-bedrock-runtime';
import { S3Client, GetObjectCommand, PutObjectCommand } from '@aws-sdk/client-s3';
import { DynamoDBClient } from '@aws-sdk/client-dynamodb';
import { DynamoDBDocumentClient, PutCommand } from '@aws-sdk/lib-dynamodb';

import { BLOG_PERSONA_SYSTEM_PROMPT } from './prompts/blog-persona.js';

// =============================================================================
// ENVIRONMENT & CLIENTS
// =============================================================================

const ASSETS_BUCKET = process.env.ASSETS_BUCKET!;
const DRAFT_PREFIX = process.env.DRAFT_PREFIX ?? 'drafts/';
const PUBLISHED_PREFIX = process.env.PUBLISHED_PREFIX ?? 'published/';
const CONTENT_PREFIX = process.env.CONTENT_PREFIX ?? 'content/';
const TABLE_NAME = process.env.TABLE_NAME!;
const FOUNDATION_MODEL = process.env.FOUNDATION_MODEL ?? 'anthropic.claude-sonnet-4-6';
const MAX_TOKENS = parseInt(process.env.MAX_TOKENS ?? '8192', 10);
const THINKING_BUDGET_TOKENS = parseInt(process.env.THINKING_BUDGET_TOKENS ?? '16000', 10);

const bedrockClient = new BedrockRuntimeClient({});
const s3Client = new S3Client({});
const dynamoClient = DynamoDBDocumentClient.from(new DynamoDBClient({}));

// =============================================================================
// TYPES
// =============================================================================

/**
 * Structured output from Claude's content transformation.
 *
 * metadata fields are AI-enhanced for the Metadata Brain model.
 */
interface TransformResult {
    mdxContent: string;
    metadata: {
        title: string;
        description: string;
        tags: string[];
        slug: string;
        publishDate: string;
        /** Numeric reading time in minutes (e.g. 8) */
        readingTime: number;
        category: string;
        /** 2–3 sentence SEO teaser generated by Bedrock */
        aiSummary: string;
        /** AI-scored technical accuracy rating (0–100) */
        technicalConfidence: number;
        /** Hero image URL for article cards and social sharing */
        heroImageUrl?: string;
    };
}

/**
 * Complexity tier classification for Adaptive Thinking budget.
 *
 * The tier drives how much "thinking time" Claude gets:
 * - LOW:  Short, narrative-heavy posts — minimal reasoning needed
 * - MID:  Standard DevOps articles with some code — moderate reasoning
 * - HIGH: Dense IaC, multi-service architectures — maximum reasoning
 */
type ComplexityTier = 'LOW' | 'MID' | 'HIGH';

/**
 * Result of the static complexity analysis performed on the raw markdown.
 */
interface ComplexityAnalysis {
    /** Classified complexity tier */
    tier: ComplexityTier;
    /** Adaptive Thinking budget tokens for this tier */
    budgetTokens: number;
    /** Human-readable reasoning for the classification */
    reason: string;
    /** Raw signal values used to determine the tier */
    signals: {
        charCount: number;
        codeBlockCount: number;
        codeRatio: number;
        yamlFrontmatterBlocks: number;
        uniqueHeadingCount: number;
    };
}

// =============================================================================
// COMPLEXITY ANALYSIS — drives Adaptive Thinking budget
// =============================================================================

/**
 * Budget tokens per complexity tier.
 * These are clamped to the env var ceiling (THINKING_BUDGET_TOKENS).
 *
 * LOW  — 2 048 tokens:  enough for simple reformatting
 * MID  — 8 192 tokens:  standard DevOps articles
 * HIGH — budget ceiling: deep reasoning for dense IaC/multi-service posts
 */
const TIER_BUDGETS: Record<ComplexityTier, number> = {
    LOW: 2_048,
    MID: 8_192,
    HIGH: THINKING_BUDGET_TOKENS, // env var ceiling
};

/**
 * Analyse the raw markdown to classify its technical complexity.
 *
 * Signals inspected:
 * 1. **Length** — character count correlates with breadth of content
 * 2. **Code density** — ratio of fenced-code-block chars to total chars
 * 3. **Code block count** — number of distinct ``` fenced blocks
 * 4. **YAML/config blocks** — yaml/yml/toml/hcl code fences (IaC indicator)
 * 5. **Heading depth** — number of unique headings (structural complexity)
 */
export function analyseComplexity(markdown: string): ComplexityAnalysis {
    const charCount = markdown.length;

    // Count fenced code blocks and their total character length
    const codeBlockRegex = /```[\s\S]*?```/g;
    const codeBlocks = markdown.match(codeBlockRegex) ?? [];
    const codeBlockCount = codeBlocks.length;
    const codeChars = codeBlocks.reduce((sum, block) => sum + block.length, 0);
    const codeRatio = charCount > 0 ? codeChars / charCount : 0;

    // Count IaC-specific code fences (yaml, hcl, toml, terraform, dockerfile)
    const iacFenceRegex = /```(?:ya?ml|hcl|terraform|toml|dockerfile|Dockerfile)/gi;
    const yamlFrontmatterBlocks = (markdown.match(iacFenceRegex) ?? []).length;

    // Count unique headings (## or ###)
    const headingRegex = /^#{1,4}\s+.+$/gm;
    const uniqueHeadingCount = (markdown.match(headingRegex) ?? []).length;

    // ---- Classification logic ----
    let tier: ComplexityTier;
    let reason: string;

    const isLong = charCount > 8_000;
    const isCodeHeavy = codeRatio > 0.30;
    const hasManyCodeBlocks = codeBlockCount >= 6;
    const hasIacBlocks = yamlFrontmatterBlocks >= 2;
    const isStructurallyComplex = uniqueHeadingCount >= 8;

    // HIGH: meets ≥ 2 of the "heavy" signals
    const heavySignals = [isLong && isCodeHeavy, hasManyCodeBlocks, hasIacBlocks, isStructurallyComplex];
    const heavyCount = heavySignals.filter(Boolean).length;

    if (heavyCount >= 2) {
        tier = 'HIGH';
        reason = `Dense technical content (${codeBlockCount} code blocks, ${(codeRatio * 100).toFixed(0)}% code, ${yamlFrontmatterBlocks} IaC fences, ${uniqueHeadingCount} headings)`;
    } else if (isLong || hasManyCodeBlocks || isCodeHeavy) {
        tier = 'MID';
        reason = `Moderate complexity (${codeBlockCount} code blocks, ${(codeRatio * 100).toFixed(0)}% code, ${charCount.toLocaleString()} chars)`;
    } else {
        tier = 'LOW';
        reason = `Light content (${codeBlockCount} code blocks, ${charCount.toLocaleString()} chars)`;
    }

    return {
        tier,
        budgetTokens: Math.min(TIER_BUDGETS[tier], THINKING_BUDGET_TOKENS),
        reason,
        signals: {
            charCount,
            codeBlockCount,
            codeRatio: Math.round(codeRatio * 100) / 100,
            yamlFrontmatterBlocks,
            uniqueHeadingCount,
        },
    };
}

// =============================================================================
// HELPER FUNCTIONS
// =============================================================================

/**
 * Read the raw markdown file from S3
 */
async function readDraftFromS3(bucket: string, key: string): Promise<string> {
    const response = await s3Client.send(new GetObjectCommand({
        Bucket: bucket,
        Key: key,
    }));

    return await response.Body!.transformToString('utf-8');
}

/**
 * Write the transformed MDX file to S3.
 *
 * Writes to TWO locations:
 * 1. published/<slug>.mdx   — backward-compatible flat output
 * 2. content/v<n>/<slug>.mdx — versioned content blob (Metadata Brain)
 */
async function writeContentToS3(
    bucket: string,
    publishedKey: string,
    contentKey: string,
    content: string,
): Promise<void> {
    // Write both locations in parallel
    await Promise.all([
        s3Client.send(new PutObjectCommand({
            Bucket: bucket,
            Key: publishedKey,
            Body: content,
            ContentType: 'text/mdx',
        })),
        s3Client.send(new PutObjectCommand({
            Bucket: bucket,
            Key: contentKey,
            Body: content,
            ContentType: 'text/mdx',
        })),
    ]);
}

/**
 * Write AI-enhanced metadata to DynamoDB using the Metadata Brain entity model.
 *
 * Two records per article:
 *
 * 1. METADATA (sk: "METADATA") — the clean, consumer-facing record.
 *    This is what the Next.js app on K8s queries to render article cards.
 *    Shape matches the "Modified Brain Entity" spec:
 *    ```json
 *    {
 *      "pk": "ARTICLE#devsecops-pipeline",
 *      "sk": "METADATA",
 *      "title": "DevSecOps Pipeline: 30 Custom Checkov Rules",
 *      "tags": ["Security", "CDK"],
 *      "heroImageUrl": "https://cdn.example.com/assets/hero.png",
 *      "contentRef": "s3://my-bucket/published/devsecops-pipeline.mdx",
 *      "aiSummary": "A deep dive into 30 custom rules...",
 *      "readingTime": 8
 *    }
 *    ```
 *
 * 2. CONTENT version (sk: "CONTENT#v_{ts}") — immutable audit record.
 *    Stores all enrichment fields (description, category, complexity, etc.)
 *    for pipeline diagnostics and version history.
 */
async function writeMetadataToDynamoDB(
    slug: string,
    metadata: TransformResult['metadata'],
    sourceKey: string,
    publishedKey: string,
    complexity: ComplexityAnalysis,
): Promise<void> {
    const now = new Date().toISOString();
    const pk = `ARTICLE#${slug}`;
    const contentRef = `s3://${ASSETS_BUCKET}/${publishedKey}`;

    // 1. METADATA record — clean, consumer-facing entity
    //    Only the fields the Next.js app needs to render article cards.
    await dynamoClient.send(new PutCommand({
        TableName: TABLE_NAME,
        Item: {
            pk,
            sk: 'METADATA',
            title: metadata.title,
            tags: metadata.tags,
            heroImageUrl: metadata.heroImageUrl ?? '',
            contentRef,
            aiSummary: metadata.aiSummary,
            readingTime: metadata.readingTime,
        },
    }));

    // 2. CONTENT version record — immutable audit trail
    //    Full enrichment for pipeline diagnostics and version history.
    await dynamoClient.send(new PutCommand({
        TableName: TABLE_NAME,
        Item: {
            pk,
            sk: `CONTENT#v_${now}`,
            title: metadata.title,
            description: metadata.description,
            tags: metadata.tags,
            slug: metadata.slug,
            publishDate: metadata.publishDate,
            readingTime: metadata.readingTime,
            category: metadata.category,
            aiSummary: metadata.aiSummary,
            technicalConfidence: metadata.technicalConfidence,
            heroImageUrl: metadata.heroImageUrl ?? '',
            contentRef,
            sourceKey,
            transformedAt: now,
            model: FOUNDATION_MODEL,
            complexityTier: complexity.tier,
            complexityReason: complexity.reason,
            thinkingBudgetUsed: complexity.budgetTokens,
        },
    }));
}

/**
 * Derive the published S3 key (backward-compatible flat output).
 * Input:  drafts/my-article.md
 * Output: published/my-article.mdx
 */
function derivePublishedKey(draftKey: string): string {
    const filename = draftKey
        .replace(DRAFT_PREFIX, '')
        .replace(/\.md$/, '.mdx');
    return `${PUBLISHED_PREFIX}${filename}`;
}

/**
 * Derive the versioned content blob S3 key (Metadata Brain).
 * Input:  drafts/my-article.md, version 1
 * Output: content/v1/my-article.mdx
 */
function deriveContentKey(draftKey: string, version: number): string {
    const filename = draftKey
        .replace(DRAFT_PREFIX, '')
        .replace(/\.md$/, '.mdx');
    return `${CONTENT_PREFIX}v${version}/${filename}`;
}

/**
 * Derive a slug from the draft filename.
 * Input:  drafts/deploying-k8s-on-aws.md
 * Output: deploying-k8s-on-aws
 */
function deriveSlug(draftKey: string): string {
    return draftKey
        .replace(DRAFT_PREFIX, '')
        .replace(/\.md$/, '');
}

/**
 * Parse Claude's response into structured TransformResult.
 * Expects a JSON object in the text response.
 */
function parseTransformResult(responseText: string): TransformResult {
    // Claude may wrap JSON in markdown code fences
    const jsonMatch = responseText.match(/```(?:json)?\s*\n?([\s\S]*?)\n?```/);
    const jsonStr = jsonMatch ? jsonMatch[1].trim() : responseText.trim();

    const parsed = JSON.parse(jsonStr) as TransformResult;

    // Validate required fields
    if (!parsed.mdxContent || !parsed.metadata?.slug) {
        throw new Error('Invalid transform result: missing mdxContent or metadata.slug');
    }

    // Coerce readingTime to number if Claude returns a string
    if (typeof parsed.metadata.readingTime === 'string') {
        parsed.metadata.readingTime = parseInt(parsed.metadata.readingTime, 10) || 5;
    }

    // Clamp technicalConfidence to 0-100
    if (typeof parsed.metadata.technicalConfidence === 'number') {
        parsed.metadata.technicalConfidence = Math.max(0, Math.min(100, parsed.metadata.technicalConfidence));
    } else {
        parsed.metadata.technicalConfidence = 0;
    }

    return parsed;
}

/**
 * Call Claude 4.6 Sonnet via the Bedrock Converse API with
 * Prompt Caching and Adaptive Thinking.
 *
 * The thinking budget is dynamically scaled based on the
 * complexity analysis of the input markdown.
 */
async function transformWithBedrock(
    markdownContent: string,
    slug: string,
    complexity: ComplexityAnalysis,
): Promise<TransformResult> {
    const command = new ConverseCommand({
        modelId: FOUNDATION_MODEL,
        system: BLOG_PERSONA_SYSTEM_PROMPT,
        messages: [
            {
                role: 'user',
                content: [
                    {
                        text: [
                            `Transform the following raw markdown draft into a polished MDX blog post.`,
                            `The article slug is: "${slug}"`,
                            `Today's date is: ${new Date().toISOString().split('T')[0]}`,
                            ``,
                            `## Complexity Assessment`,
                            `This draft has been classified as **${complexity.tier}** complexity.`,
                            `Reason: ${complexity.reason}`,
                            ``,
                            `### Adaptive Detail Preservation Rules`,
                            complexity.tier === 'HIGH'
                                ? [
                                    `- This is a HIGHLY technical article. Preserve ALL code blocks, configs, and CLI commands verbatim.`,
                                    `- Maintain every architectural detail, flag, and parameter from the original.`,
                                    `- Add explanatory comments to code blocks where the author hasn't provided them.`,
                                    `- Expand abbreviated explanations into full technical reasoning.`,
                                    `- Include a detailed Prerequisites section.`,
                                ].join('\n')
                                : complexity.tier === 'MID'
                                    ? [
                                        `- Preserve all code blocks and commands exactly as written.`,
                                        `- Add brief context around code examples where helpful.`,
                                        `- Balance narrative flow with technical precision.`,
                                    ].join('\n')
                                    : [
                                        `- Focus on readability and narrative flow.`,
                                        `- Keep code examples but prioritise the storytelling.`,
                                        `- Light-touch editing — polish rather than restructure.`,
                                    ].join('\n'),
                            ``,
                            `--- BEGIN DRAFT ---`,
                            markdownContent,
                            `--- END DRAFT ---`,
                            ``,
                            `Return ONLY the JSON object as specified in the system prompt. No additional text.`,
                        ].join('\n'),
                    },
                ],
            },
        ],
        inferenceConfig: {
            maxTokens: MAX_TOKENS,
            temperature: complexity.tier === 'HIGH' ? 0.2 : complexity.tier === 'MID' ? 0.3 : 0.4,
        },
        additionalModelRequestFields: {
            thinking: {
                type: 'enabled',
                budgetTokens: complexity.budgetTokens,
            },
        },
    });

    const response = await bedrockClient.send(command);

    // Extract text from output content blocks (skip thinking blocks)
    const outputBlocks = response.output?.message?.content ?? [];
    const textContent = outputBlocks
        .filter((block: Record<string, unknown>): block is { text: string } =>
            'text' in block && typeof block.text === 'string')
        .map((block: { text: string }) => block.text)
        .join('');

    if (!textContent) {
        throw new Error('No text content in Bedrock Converse response');
    }

    return parseTransformResult(textContent);
}

// =============================================================================
// LAMBDA HANDLER
// =============================================================================

/**
 * S3 event handler for the MD-to-Blog pipeline.
 *
 * Triggered by s3:ObjectCreated on drafts/*.md.
 * Analyses input complexity, scales Adaptive Thinking budget,
 * then transforms each draft via Claude 4.6 and writes results
 * using the Metadata Brain model.
 */
export const handler: S3Handler = async (event: S3Event): Promise<void> => {
    console.log(`Processing ${event.Records.length} S3 event(s)`);

    for (const record of event.Records) {
        const bucket = record.s3.bucket.name;
        const key = decodeURIComponent(record.s3.object.key.replace(/\+/g, ' '));

        console.log(`Processing draft: s3://${bucket}/${key}`);

        try {
            // 1. Read the raw markdown from S3
            const markdownContent = await readDraftFromS3(bucket, key);
            console.log(`Read ${markdownContent.length} chars from draft`);

            // 2. Analyse complexity → drives thinking budget
            const complexity = analyseComplexity(markdownContent);
            console.log(
                `Complexity: ${complexity.tier} → ${complexity.budgetTokens} thinking tokens | ${complexity.reason}`,
            );

            // 3. Derive output paths
            const slug = deriveSlug(key);
            const publishedKey = derivePublishedKey(key);
            const contentKey = deriveContentKey(key, 1); // v1 for initial publish

            // 4. Transform via Bedrock Converse API (budget scales with complexity)
            console.log(`Invoking ${FOUNDATION_MODEL} with Adaptive Thinking (budget: ${complexity.budgetTokens} tokens)`);
            const result = await transformWithBedrock(markdownContent, slug, complexity);
            console.log(`Transform complete: "${result.metadata.title}" (${result.metadata.readingTime} min, confidence: ${result.metadata.technicalConfidence}%)`);

            // 5. Write MDX content to S3 (published/ + content/v1/)
            await writeContentToS3(ASSETS_BUCKET, publishedKey, contentKey, result.mdxContent);
            console.log(`Content written to s3://${ASSETS_BUCKET}/${publishedKey} + ${contentKey}`);

            // 6. Write AI-enhanced metadata to DynamoDB (Metadata Brain)
            await writeMetadataToDynamoDB(
                result.metadata.slug || slug,
                result.metadata,
                key,
                publishedKey,
                complexity,
            );
            console.log(`Metadata written to ${TABLE_NAME} (pk=ARTICLE#${result.metadata.slug || slug})`);

        } catch (error) {
            console.error(`Failed to process ${key}:`, error);
            throw error; // Let Lambda retry / send to DLQ
        }
    }

    console.log('All records processed successfully');
};
