#!/usr/bin/env bash
# =============================================================================
# verify-cluster.sh — Post-Deployment Verification Script
#
# Run this on the CONTROL PLANE node after initial deployment.
# It tests the full stack (cluster → networking → workloads → connectivity)
# and reports detailed, actionable error messages for every failure.
#
# Usage:
#   chmod +x verify-cluster.sh && ./verify-cluster.sh
#   ./verify-cluster.sh --skip-connectivity   # skip external curl tests
#   ./verify-cluster.sh --json                # output summary as JSON
#
# Reference: docs/kubernetes/post-deployment-verification-guide.md
# =============================================================================
set -euo pipefail

# ---------------------------------------------------------------------------
# Colour helpers (degrade gracefully if not a TTY)
# ---------------------------------------------------------------------------
if [ -t 1 ]; then
  RED='\033[0;31m'; GRN='\033[0;32m'; YLW='\033[0;33m'
  BLU='\033[0;34m'; CYN='\033[0;36m'; BLD='\033[1m'; RST='\033[0m'
else
  RED=''; GRN=''; YLW=''; BLU=''; CYN=''; BLD=''; RST=''
fi

# ---------------------------------------------------------------------------
# Counters & flags
# ---------------------------------------------------------------------------
PASS=0; FAIL=0; WARN=0; SKIP=0
SKIP_CONNECTIVITY=false
JSON_OUTPUT=false
FAILURES=()     # accumulate failure descriptions for final summary
WARNINGS=()     # accumulate warning descriptions for final summary

for arg in "$@"; do
  case "$arg" in
    --skip-connectivity) SKIP_CONNECTIVITY=true ;;
    --json)              JSON_OUTPUT=true ;;
  esac
done

# ---------------------------------------------------------------------------
# Helper functions
# ---------------------------------------------------------------------------
section() {
  echo ""
  echo -e "${BLD}${BLU}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${RST}"
  echo -e "${BLD}${BLU}  $1${RST}"
  echo -e "${BLD}${BLU}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${RST}"
}

pass() {
  echo -e "  ${GRN}✅ PASS${RST}  $1"
  ((PASS++))
}

fail() {
  echo -e "  ${RED}❌ FAIL${RST}  $1"
  ((FAIL++))
  FAILURES+=("$1")
  # Print the detailed troubleshooting block (indented)
  if [ -n "${2:-}" ]; then
    echo ""
    echo -e "${RED}  ┌─ What failed & why ──────────────────────────────────────────────────────${RST}"
    # Use while-read to properly handle the multi-line string
    while IFS= read -r line; do
      echo -e "${RED}  │${RST}  $line"
    done <<< "$2"
    echo -e "${RED}  └────────────────────────────────────────────────────────────────────────────${RST}"
    echo ""
  fi
}

warn() {
  echo -e "  ${YLW}⚠️  WARN${RST}  $1"
  ((WARN++))
  WARNINGS+=("$1")
  if [ -n "${2:-}" ]; then
    echo ""
    echo -e "${YLW}  ┌─ Details ─────────────────────────────────────────────────────────────────${RST}"
    while IFS= read -r line; do
      echo -e "${YLW}  │${RST}  $line"
    done <<< "$2"
    echo -e "${YLW}  └────────────────────────────────────────────────────────────────────────────${RST}"
    echo ""
  fi
}

skip() {
  echo -e "  ${CYN}⏭️  SKIP${RST}  $1"
  ((SKIP++))
}

info() {
  echo -e "  ${BLU}ℹ️  INFO${RST}  $1"
}

# Safely run kubectl and capture output + exit code
kube() {
  kubectl "$@" 2>&1
}

# ---------------------------------------------------------------------------
# Pre-flight: ensure we can talk to the cluster
# ---------------------------------------------------------------------------
section "0 — Pre-flight: kubectl Access"

echo -e "  Checking KUBECONFIG..."
if [ -z "${KUBECONFIG:-}" ]; then
  if [ -f /etc/kubernetes/admin.conf ]; then
    export KUBECONFIG=/etc/kubernetes/admin.conf
    warn "KUBECONFIG was not set — auto-detected /etc/kubernetes/admin.conf" \
"KUBECONFIG environment variable was empty.
This means your shell session did not source /etc/profile.d/kubernetes.sh.

COMPONENT: KUBECONFIG is the environment variable that tells kubectl where to
find the cluster credentials (certificate + API server address).

FIX (this session):
  export KUBECONFIG=/etc/kubernetes/admin.conf

FIX (permanent for SSM sessions):
  The boot script should have written this to /etc/bashrc.
  Check with:  grep KUBECONFIG /etc/bashrc"
  else
    fail "kubectl not configured — /etc/kubernetes/admin.conf not found" \
"The kubeconfig file /etc/kubernetes/admin.conf does not exist.

COMPONENT: admin.conf is generated by 'kubeadm init' during the cluster
bootstrap. It contains the CA certificate, the admin client certificate,
and the API server endpoint. Without it, kubectl cannot authenticate.

ROOT CAUSE: 'kubeadm init' either never ran, or failed before generating
certificates. This usually happens because:
  1. The boot script (boot-k8s.sh) was never downloaded from S3
  2. ip_forward was not enabled (/proc/sys/net/ipv4/ip_forward != 1)
  3. containerd was not running when kubeadm tried to start pods

WHERE TO LOOK:
  sudo tail -200 /var/log/cloud-init-output.log
  sudo ls -la /etc/kubernetes/
  sudo systemctl status containerd

RECOVERY: See post-deployment-verification-guide.md Section 17
'Cluster Not Initialized' for the full kubeadm init manual procedure."
    echo ""
    echo -e "${RED}Cannot proceed without cluster access. Exiting.${RST}"
    exit 1
  fi
fi

# Test connectivity
if kube cluster-info &>/dev/null; then
  pass "kubectl connected to cluster"
  kube cluster-info 2>/dev/null | head -2 | sed 's/^/          /'
else
  fail "kubectl cannot reach the API server" \
"The kubectl command failed to connect to the Kubernetes API server.

COMPONENT: The API server (kube-apiserver) is the central management hub.
Every kubectl command, every pod scheduling decision, and every controller
loop communicates through it. It runs as a static pod on the control plane.

POSSIBLE CAUSES:
  1. API server pod crashed — check:
     sudo crictl ps | grep kube-apiserver
     sudo journalctl -u kubelet --no-pager --lines=50

  2. Certificates expired — check:
     sudo kubeadm certs check-expiration

  3. etcd is down (API server depends on etcd for storage) — check:
     sudo crictl ps | grep etcd

WHERE TO LOOK:
  sudo journalctl -u kubelet --no-pager --lines=100
  sudo cat /var/log/containers/kube-apiserver-*.log | tail -50"
  echo ""
  echo -e "${RED}Cannot proceed without cluster access. Exiting.${RST}"
  exit 1
fi

# =============================================================================
# CHECK 1 — Nodes
# =============================================================================
section "1 — Cluster Nodes (expect 3: 1 control-plane + 2 workers)"

NODE_OUTPUT=$(kube get nodes -o wide --no-headers)
NODE_COUNT=$(echo "$NODE_OUTPUT" | wc -l | tr -d ' ')
READY_COUNT=$(echo "$NODE_OUTPUT" | grep -c " Ready " || true)
NOTREADY_NODES=$(echo "$NODE_OUTPUT" | grep -v " Ready " || true)

echo "$NODE_OUTPUT" | sed 's/^/          /'
echo ""

if [ "$NODE_COUNT" -eq 3 ]; then
  pass "Node count: $NODE_COUNT/3"
elif [ "$NODE_COUNT" -gt 0 ]; then
  fail "Node count: $NODE_COUNT/3 — workers may not have joined" \
"Expected 3 nodes (1 control-plane + 2 workers), but found $NODE_COUNT.

COMPONENT: Worker nodes run your application pods. They join the cluster
by connecting to the control plane's API server using a bootstrap token
generated by kubeadm. If a worker is missing, it either:
  1. Failed to download boot-worker.sh from S3
  2. The join token expired (tokens last 24 hours by default)
  3. Security group blocks port 6443 between worker and control plane

DIAGNOSTIC (run on control plane):
  # Generate a fresh join command:
  sudo kubeadm token create --print-join-command

  # Check if workers are registered at all:
  kubectl get nodes -o wide

DIAGNOSTIC (SSM into the missing worker):
  sudo tail -200 /var/log/cloud-init-output.log
  sudo systemctl status kubelet
  sudo journalctl -u kubelet --no-pager --lines=30"
else
  fail "No nodes found — cluster may not be initialized" ""
fi

if [ "$READY_COUNT" -eq "$NODE_COUNT" ] && [ "$NODE_COUNT" -gt 0 ]; then
  pass "All $READY_COUNT nodes are Ready"
elif [ -n "$NOTREADY_NODES" ]; then
  fail "Some nodes are NOT Ready" \
"The following nodes are not in Ready state:
$(echo "$NOTREADY_NODES" | awk '{print "  - " $1 " (Status: " $2 ")"}')

COMPONENT: A node's Ready status is reported by the kubelet daemon.
kubelet runs on every node and is responsible for starting pods,
reporting node health, and managing container lifecycle.

CAUSES OF NotReady:
  1. kubelet crashed or was stopped
     → SSM into the node: sudo systemctl status kubelet
  2. Container runtime (containerd) is down
     → SSM into the node: sudo systemctl status containerd
  3. CNI plugin (Calico) is not running on that node
     → kubectl get pods -n calico-system -o wide | grep <node-name>
  4. Node ran out of disk space
     → SSM into the node: df -h

WHERE TO LOOK: SSM into the affected node and run:
  sudo journalctl -u kubelet --no-pager --lines=50"
fi

# =============================================================================
# CHECK 2 — Node Labels & Taints
# =============================================================================
section "2 — Node Labels & Taints"

# Check for role labels on workers
APP_NODES=$(kube get nodes -l role=application --no-headers 2>/dev/null | wc -l | tr -d ' ')
MON_NODES=$(kube get nodes -l role=monitoring --no-headers 2>/dev/null | wc -l | tr -d ' ')

if [ "$APP_NODES" -ge 1 ]; then
  pass "Application worker found (role=application label present)"
else
  fail "No node with label role=application" \
"No worker node has the label 'role=application'.

COMPONENT: Node labels are key-value pairs attached to nodes. The NextJS
Helm chart uses 'nodeSelector: { role: application }' to ensure pods only
schedule on the application worker. Without this label, NextJS pods will
stay in Pending state with the event:
  'Warning FailedScheduling: 0/3 nodes are available: ... node(s) didn't
   match Pod's node affinity/selector'

WHERE IS IT SET: The label is applied by boot-worker.sh using the
NODE_LABEL environment variable passed from CDK user data:
  kubectl label node <node-name> role=application

FIX (manual):
  # Find the application worker (check instance tags in AWS console)
  kubectl label node <node-name> role=application

FIX (permanent): Ensure the CDK stack passes NODE_LABEL=application
in the application worker's user data."
fi

if [ "$MON_NODES" -ge 1 ]; then
  pass "Monitoring worker found (role=monitoring label present)"
else
  fail "No node with label role=monitoring" \
"No worker node has the label 'role=monitoring'.

COMPONENT: The monitoring Helm chart uses 'nodeSelector: { role: monitoring }'
to keep Prometheus, Grafana, Loki, Tempo, and other observability tools on a
dedicated worker. Without this label, monitoring pods stay in Pending.

FIX (manual):
  kubectl label node <node-name> role=monitoring

FIX (permanent): Ensure the CDK stack passes NODE_LABEL=monitoring
in the monitoring worker's user data."
fi

# Check control plane taint
CP_NODE=$(kube get nodes --selector='node-role.kubernetes.io/control-plane' -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
if [ -n "$CP_NODE" ]; then
  CP_TAINTS=$(kube get node "$CP_NODE" -o jsonpath='{.spec.taints[*].key}' 2>/dev/null || echo "")
  if echo "$CP_TAINTS" | grep -q "node-role.kubernetes.io/control-plane"; then
    pass "Control plane taint is present (NoSchedule) — only Traefik/system DaemonSets can schedule here"
  else
    warn "Control plane taint is MISSING — regular workloads can schedule on control plane" \
"The control plane node does not have the taint:
  node-role.kubernetes.io/control-plane:NoSchedule

COMPONENT: Taints prevent pods from scheduling on a node unless they have
a matching toleration. The control plane should be reserved for system
components (etcd, API server, scheduler, controller-manager). Traefik
has a toleration that allows it to run here as a DaemonSet.

WHY IT MATTERS: Without this taint, application and monitoring pods could
be scheduled on the control plane, competing with core Kubernetes components
for CPU and memory. This can destabilize the cluster.

FIX:
  kubectl taint nodes $CP_NODE node-role.kubernetes.io/control-plane:NoSchedule"
  fi
else
  warn "Could not identify control plane node"
fi

# =============================================================================
# CHECK 3 — System Pods (kube-system)
# =============================================================================
section "3 — System Pods (kube-system)"

SYSTEM_PODS=$(kube get pods -n kube-system --no-headers)
echo "$SYSTEM_PODS" | sed 's/^/          /'
echo ""

# Check for essential system pods
ESSENTIAL_PODS=("kube-apiserver" "kube-controller-manager" "kube-scheduler" "etcd" "coredns" "kube-proxy")
ESSENTIAL_DESCRIPTIONS=(
  "kube-apiserver|The API server is the front door to the cluster. Every kubectl command, every pod scheduling decision, and every internal controller goes through it. It runs as a static pod managed by the kubelet (not a Deployment). If it's missing, the kubelet may have failed to read its manifest from /etc/kubernetes/manifests/kube-apiserver.yaml."
  "kube-controller-manager|The controller manager watches the desired state (Deployments, ReplicaSets) and ensures the actual state matches. For example, if a Deployment says '2 replicas' but only 1 pod exists, the controller manager creates the missing pod. Without it, self-healing stops working."
  "kube-scheduler|The scheduler decides which node each new pod runs on, based on resource requests, node labels, taints/tolerations, and affinity rules. Without it, new pods stay in Pending forever because nothing assigns them to a node."
  "etcd|etcd is the cluster's database — it stores every Kubernetes object (pods, services, secrets, config maps). It's a distributed key-value store running as a static pod. If etcd is down, the API server cannot read or write any state, which makes the entire cluster non-functional."
  "coredns|CoreDNS provides internal DNS resolution. When a pod connects to 'grafana.monitoring.svc.cluster.local', CoreDNS resolves that name to the Grafana service's ClusterIP. Without it, pods cannot discover other services by name — only by raw IP address."
  "kube-proxy|kube-proxy manages iptables/ipvs rules on each node so that traffic sent to a Service's ClusterIP gets load-balanced to the correct backend pods. Without it, Services stop routing traffic."
)

for i in "${!ESSENTIAL_PODS[@]}"; do
  POD_NAME="${ESSENTIAL_PODS[$i]}"
  IFS='|' read -r short_name description <<< "${ESSENTIAL_DESCRIPTIONS[$i]}"

  MATCHING=$(echo "$SYSTEM_PODS" | grep "$POD_NAME" || true)
  if [ -z "$MATCHING" ]; then
    fail "$POD_NAME pod NOT found in kube-system" \
"$description

WHERE TO LOOK:
  kubectl get pods -n kube-system
  sudo crictl ps -a | grep $POD_NAME
  sudo journalctl -u kubelet --no-pager --lines=50"
  else
    RUNNING=$(echo "$MATCHING" | grep "Running" || true)
    if [ -n "$RUNNING" ]; then
      pass "$POD_NAME is Running"
    else
      STATUS=$(echo "$MATCHING" | awk '{print $3}' | head -1)
      fail "$POD_NAME is NOT Running (status: $STATUS)" \
"$description

CURRENT STATUS: $STATUS
DIAGNOSTIC:
  kubectl describe pod \$(kubectl get pods -n kube-system | grep $POD_NAME | awk '{print \$1}') -n kube-system
  kubectl logs \$(kubectl get pods -n kube-system | grep $POD_NAME | awk '{print \$1}') -n kube-system --tail=50"
    fi
  fi
done

# Check metrics-server
METRICS_PODS=$(echo "$SYSTEM_PODS" | grep "metrics-server" || true)
if [ -n "$METRICS_PODS" ]; then
  if echo "$METRICS_PODS" | grep -q "Running"; then
    pass "metrics-server is Running"
  else
    warn "metrics-server exists but is not Running" \
"COMPONENT: The Metrics Server collects CPU/memory usage from each node's
kubelet and exposes it via the Kubernetes Metrics API. It is required for:
  - 'kubectl top nodes' and 'kubectl top pods' commands
  - Horizontal Pod Autoscaler (HPA) — it reads CPU/memory from this API

Without it, the HPA for Next.js cannot scale pods based on resource usage.

DIAGNOSTIC:
  kubectl logs -n kube-system \$(kubectl get pods -n kube-system | grep metrics-server | awk '{print \$1}') --tail=30"
  fi
else
  warn "metrics-server not found" \
"COMPONENT: The Metrics Server is required for 'kubectl top' and HPA.
It should be installed by the boot script. Check:
  grep -i 'metrics-server' /var/log/cloud-init-output.log"
fi

# =============================================================================
# CHECK 4 — Namespaces
# =============================================================================
section "4 — Namespaces"

NAMESPACES=$(kube get namespaces --no-headers | awk '{print $1}')
echo "$NAMESPACES" | sed 's/^/          /'
echo ""

EXPECTED_NS=("nextjs-app" "monitoring" "argocd" "calico-system" "tigera-operator")
NS_DESCRIPTIONS=(
  "nextjs-app|Hosts the Next.js portfolio application pods, services, and HPA. Created by ArgoCD when syncing the nextjs Application (syncOptions: CreateNamespace=true)."
  "monitoring|Hosts the full observability stack: Prometheus, Grafana, Loki, Tempo, Promtail, Node Exporter, Kube State Metrics. Created by ArgoCD when syncing the monitoring Application."
  "argocd|Hosts the ArgoCD GitOps controller that syncs Git → cluster. Created by bootstrap_argocd.py during the boot sequence."
  "calico-system|Hosts the Calico CNI data-plane pods (calico-node DaemonSet, calico-typha, calico-kube-controllers). Calico provides pod-to-pod networking and NetworkPolicy enforcement. Created by the Tigera operator."
  "tigera-operator|Hosts the Tigera operator that manages the Calico CNI lifecycle. Installed by boot-k8s.sh via kubectl apply on the Tigera operator manifest."
)

for i in "${!EXPECTED_NS[@]}"; do
  NS_NAME="${EXPECTED_NS[$i]}"
  IFS='|' read -r short_name ns_desc <<< "${NS_DESCRIPTIONS[$i]}"

  if echo "$NAMESPACES" | grep -qw "$NS_NAME"; then
    pass "Namespace '$NS_NAME' exists"
  else
    fail "Namespace '$NS_NAME' is MISSING" \
"$ns_desc

WHY IT'S MISSING: The component that creates this namespace has not run yet.
Namespaces are created by:
  - nextjs-app  → ArgoCD syncs the nextjs Application (CreateNamespace=true)
  - monitoring  → ArgoCD syncs the monitoring Application (CreateNamespace=true)
  - argocd      → bootstrap_argocd.py (creates ns before installing ArgoCD)
  - calico-*    → boot-k8s.sh (kubectl apply tigera-operator)

WHERE TO LOOK:
  kubectl get application -n argocd
  kubectl describe application <app-name> -n argocd
  sudo tail -200 /var/log/cloud-init-output.log"
  fi
done

# =============================================================================
# CHECK 5 — Calico CNI Networking
# =============================================================================
section "5 — Calico CNI (Pod Networking)"

CALICO_PODS=$(kube get pods -n calico-system --no-headers 2>/dev/null || echo "")
if [ -z "$CALICO_PODS" ]; then
  fail "No pods in calico-system namespace" \
"COMPONENT: Calico is the Container Network Interface (CNI) plugin. It assigns
IP addresses to pods and creates virtual network routes so pods on different
nodes can communicate. Without a working CNI, pods cannot start — they will be
stuck in ContainerCreating with the error:
  'networkPlugin cni failed to set up pod network'

Calico also enforces NetworkPolicy rules (firewall between pods).

ROOT CAUSE: The Tigera operator may not have been installed. boot-k8s.sh
applies the Tigera operator manifest, which then creates the calico-system
namespace and deploys Calico pods.

WHERE TO LOOK:
  kubectl get pods -n tigera-operator
  sudo grep -i 'tigera\|calico' /var/log/cloud-init-output.log"
else
  echo "$CALICO_PODS" | sed 's/^/          /'
  echo ""

  CALICO_RUNNING=$(echo "$CALICO_PODS" | grep -c "Running" || true)
  CALICO_TOTAL=$(echo "$CALICO_PODS" | wc -l | tr -d ' ')

  if [ "$CALICO_RUNNING" -eq "$CALICO_TOTAL" ]; then
    pass "All $CALICO_TOTAL Calico pods are Running"
  else
    fail "$CALICO_RUNNING/$CALICO_TOTAL Calico pods are Running" \
"Some Calico pods are not in Running state. This will break pod networking.

COMPONENT: Calico has several sub-components:
  - calico-node (DaemonSet) — runs on every node, manages BIRD BGP routing
  - calico-typha — a fan-out proxy that reduces API server load
  - calico-kube-controllers — syncs Calico network policy with Kubernetes

DIAGNOSTIC:
  kubectl describe pods -n calico-system | grep -A 10 'Events:'"
  fi
fi

# Tigera operator
TIGERA_PODS=$(kube get pods -n tigera-operator --no-headers 2>/dev/null || echo "")
if [ -n "$TIGERA_PODS" ] && echo "$TIGERA_PODS" | grep -q "Running"; then
  pass "Tigera operator is Running"
else
  fail "Tigera operator is NOT Running" \
"COMPONENT: The Tigera operator manages the Calico CNI lifecycle. It watches a
custom resource called 'Installation' and deploys/updates Calico pods accordingly.
Without the operator, Calico cannot be installed or upgraded.

WHERE TO LOOK:
  kubectl get pods -n tigera-operator
  kubectl describe pods -n tigera-operator"
fi

# =============================================================================
# CHECK 6 — Traefik Ingress Controller
# =============================================================================
section "6 — Traefik Ingress Controller"

TRAEFIK_PODS=$(kube get pods -A --no-headers 2>/dev/null | grep traefik || echo "")
if [ -z "$TRAEFIK_PODS" ]; then
  fail "No Traefik pods found in any namespace" \
"COMPONENT: Traefik is the ingress controller — it acts as a reverse proxy
sitting at the edge of the cluster. All incoming HTTP/HTTPS traffic enters
through Traefik, which routes it to the correct backend service based on
IngressRoute rules (e.g., requests to '/' → NextJS service).

Traefik runs as a DaemonSet with hostNetwork: true, meaning it binds directly
to the node's network interfaces (ports 80, 443). This is why CloudFront can
reach it via the Elastic IP on port 80.

If Traefik is missing:
  1. External traffic cannot reach your application
  2. Grafana dashboards are not accessible
  3. ArgoCD UI is not accessible

ROOT CAUSE: Traefik is deployed by ArgoCD. If ArgoCD has not been
bootstrapped yet, Traefik won't be installed.

WHERE TO LOOK:
  kubectl get applications -n argocd | grep traefik
  kubectl get daemonsets -A | grep traefik
  # Check if ArgoCD deployed Traefik:
  kubectl describe application traefik -n argocd 2>/dev/null"
else
  echo "$TRAEFIK_PODS" | sed 's/^/          /'
  echo ""
  TRAEFIK_RUNNING=$(echo "$TRAEFIK_PODS" | grep -c "Running" || true)
  if [ "$TRAEFIK_RUNNING" -ge 1 ]; then
    pass "Traefik is Running ($TRAEFIK_RUNNING pod(s))"
  else
    fail "Traefik pods exist but are NOT Running" \
"Traefik pods were found but are not in Running state.
Check the events and logs:
  kubectl describe pods -A -l app.kubernetes.io/name=traefik
  kubectl logs -l app.kubernetes.io/name=traefik -A --tail=30"
  fi
fi

# Check IngressRoutes (Traefik CRD)
INGRESSROUTES=$(kube get ingressroutes -A --no-headers 2>/dev/null || echo "")
if [ -n "$INGRESSROUTES" ]; then
  IR_COUNT=$(echo "$INGRESSROUTES" | wc -l | tr -d ' ')
  pass "Found $IR_COUNT IngressRoute(s)"
  echo "$INGRESSROUTES" | sed 's/^/          /'
else
  warn "No IngressRoutes found" \
"COMPONENT: IngressRoutes are Traefik-specific custom resources (CRDs) that
define routing rules (e.g., 'host(dev.nelsonlamounier.com) → nextjs-service:3000').
Without IngressRoutes, Traefik doesn't know where to send incoming traffic.

If the CRD type itself is not found (kubectl error), Traefik CRDs need to
be installed first (they come with the Traefik Helm chart/installation)."
fi

# =============================================================================
# CHECK 7 — ArgoCD
# =============================================================================
section "7 — ArgoCD (GitOps Controller)"

ARGO_PODS=$(kube get pods -n argocd --no-headers 2>/dev/null || echo "")
if [ -z "$ARGO_PODS" ]; then
  fail "No ArgoCD pods found in 'argocd' namespace" \
"COMPONENT: ArgoCD is the GitOps controller that keeps the cluster state
in sync with your Git repository. It watches for changes to Helm charts,
Kustomize manifests, and plain YAML in Git, then automatically applies
them to the cluster.

ArgoCD manages all applications via the App-of-Apps pattern:
  - root Application → discovers child Applications in applications/ directory
  - Child Applications: traefik, monitoring, nextjs, metrics-server, local-path-provisioner

ROOT CAUSE: bootstrap_argocd.py has not run yet. This script:
  1. Creates the argocd namespace
  2. Installs ArgoCD via its manifest
  3. Configures the repo SSH deploy key
  4. Applies the App-of-Apps root Application (root-app.yaml)
  5. ArgoCD then auto-discovers all child Applications from Git

WHERE TO LOOK:
  sudo grep -i 'argocd\|argo' /var/log/cloud-init-output.log
  ls -la /data/k8s-bootstrap/system/argocd/"
else
  echo "$ARGO_PODS" | sed 's/^/          /'
  echo ""

  ESSENTIAL_ARGO=("argocd-server" "argocd-repo-server" "argocd-application-controller" "argocd-redis")
  ARGO_DESCRIPTIONS=(
    "argocd-server|The ArgoCD web UI and API server. Provides the dashboard at https://<host>/argocd and the API for the argocd CLI."
    "argocd-repo-server|Clones Git repositories and renders Helm/Kustomize templates into plain YAML. This is the component that detects changes in your repo."
    "argocd-application-controller|The core reconciliation loop. It compares the desired state (Git) with the actual state (cluster) and triggers syncs/rollbacks when they diverge."
    "argocd-redis|In-memory cache for ArgoCD. Stores UI session data and speeds up repo lookups. If Redis is down, the UI becomes slow and login sessions may break."
  )

  for i in "${!ESSENTIAL_ARGO[@]}"; do
    ARGO_NAME="${ESSENTIAL_ARGO[$i]}"
    IFS='|' read -r short_name argo_desc <<< "${ARGO_DESCRIPTIONS[$i]}"

    ARGO_MATCH=$(echo "$ARGO_PODS" | grep "$ARGO_NAME" || true)
    if [ -z "$ARGO_MATCH" ]; then
      fail "$ARGO_NAME pod NOT found" "$argo_desc"
    elif echo "$ARGO_MATCH" | grep -q "Running"; then
      pass "$ARGO_NAME is Running"
    else
      STATUS=$(echo "$ARGO_MATCH" | awk '{print $3}' | head -1)
      fail "$ARGO_NAME is NOT Running (status: $STATUS)" \
"$argo_desc

DIAGNOSTIC:
  kubectl describe pod \$(kubectl get pods -n argocd | grep $ARGO_NAME | awk '{print \$1}' | head -1) -n argocd
  kubectl logs \$(kubectl get pods -n argocd | grep $ARGO_NAME | awk '{print \$1}' | head -1) -n argocd --tail=30"
    fi
  done

  # Check App-of-Apps root Application
  ROOT_APP=$(kube get application root -n argocd --no-headers 2>/dev/null || echo "")
  if [ -n "$ROOT_APP" ]; then
    ROOT_STATUS=$(echo "$ROOT_APP" | awk '{print $2}')
    ROOT_HEALTH=$(echo "$ROOT_APP" | awk '{print $3}')
    if [ "$ROOT_STATUS" = "Synced" ] && [ "$ROOT_HEALTH" = "Healthy" ]; then
      pass "App-of-Apps root is Synced + Healthy"
    else
      warn "App-of-Apps root: Status=$ROOT_STATUS Health=$ROOT_HEALTH" \
"The root Application manages all child Applications.
If it is not Synced, ArgoCD cannot discover child apps.

DIAGNOSTIC:
  kubectl describe application root -n argocd
  kubectl get applications -n argocd"
    fi
  else
    fail "App-of-Apps root Application NOT found" \
"The 'root' Application is the parent that discovers all child Applications
(traefik, monitoring, nextjs, etc.) from the applications/ directory in Git.

It should be applied by bootstrap_argocd.py via:
  kubectl apply -f root-app.yaml

WITHOUT IT: ArgoCD cannot discover or manage any applications.

DIAGNOSTIC:
  kubectl get applications -n argocd
  ls -la /data/k8s-bootstrap/system/argocd/root-app.yaml"
  fi

  # Check child ArgoCD Applications
  ARGO_APPS=$(kube get applications -n argocd --no-headers 2>/dev/null || echo "")
  if [ -n "$ARGO_APPS" ]; then
    echo ""
    APP_COUNT=$(echo "$ARGO_APPS" | wc -l | tr -d ' ')
    info "ArgoCD Applications ($APP_COUNT total):"
    echo "$ARGO_APPS" | sed 's/^/          /'

    # Check for non-Synced applications
    UNSYNCED=$(echo "$ARGO_APPS" | grep -v "Synced" | grep -v "^root " || true)
    if [ -n "$UNSYNCED" ]; then
      warn "Some child Applications are not Synced" \
"The following Applications are out of sync with Git:
$(echo "$UNSYNCED" | awk '{print "  - " $1 " (Status: " $2 ", Health: " $3 ")"}')

DIAGNOSTIC:
  kubectl describe application <app-name> -n argocd"
    fi
  else
    warn "No ArgoCD Applications found" \
"ArgoCD is running but has no Application resources.
The root Application should auto-discover child Applications from Git.

DIAGNOSTIC:
  kubectl get application root -n argocd
  kubectl describe application root -n argocd"
  fi
fi

# =============================================================================
# CHECK 8 — Monitoring Stack
# =============================================================================
section "8 — Monitoring Stack"

MON_PODS=$(kube get pods -n monitoring --no-headers 2>/dev/null || echo "")
if [ -z "$MON_PODS" ]; then
  fail "No pods in 'monitoring' namespace" \
"COMPONENT: The monitoring namespace hosts the full observability stack.
Without it, you have no metrics, logs, or distributed tracing.

The monitoring stack is deployed by ArgoCD via the 'monitoring' Application,
which syncs the Helm chart from Git. Secrets (Grafana password, GitHub token)
are pre-seeded by deploy.py on first boot.

It includes: Prometheus (metrics), Grafana (dashboards), Loki (logs),
Tempo (traces), Promtail (log shipper), Node Exporter, Kube State Metrics.

ROOT CAUSE: ArgoCD has not synced the monitoring Application. Check:
  1. The 'monitoring' Application exists: kubectl get application monitoring -n argocd
  2. The Application is Synced: kubectl describe application monitoring -n argocd
  3. The App-of-Apps root discovered it: kubectl get application root -n argocd

WHERE TO LOOK:
  kubectl describe application monitoring -n argocd
  kubectl get events -n monitoring --sort-by='.lastTimestamp'"
else
  echo "$MON_PODS" | sed 's/^/          /'
  echo ""

  MON_COMPONENTS=("prometheus" "grafana" "loki" "tempo" "kube-state-metrics")
  MON_DESCRIPTIONS=(
    "prometheus|Prometheus scrapes metrics (CPU, memory, request latency, error rates) from all services via HTTP /metrics endpoints every 15-30 seconds. It stores time-series data and provides the query language PromQL. Without it, Grafana dashboards show no data."
    "grafana|Grafana is the visualization dashboard. It queries Prometheus (metrics) and Loki (logs) to render charts, graphs, and alerts. It's the primary UI for monitoring cluster health."
    "loki|Loki is a log aggregation system — like a lightweight Elasticsearch specifically for logs. Promtail ships pod logs to Loki, which stores and indexes them. Without Loki, you can't search pod logs from the Grafana UI."
    "tempo|Tempo is a distributed tracing backend. It stores trace spans so you can follow a request as it travels across microservices. Used for debugging latency issues."
    "kube-state-metrics|Kube State Metrics exports Kubernetes object metrics: deployment replica counts, pod statuses, node conditions, PVC states. Prometheus scrapes these to power the Kubernetes-specific Grafana dashboards."
  )

  for i in "${!MON_COMPONENTS[@]}"; do
    COMP="${MON_COMPONENTS[$i]}"
    IFS='|' read -r short_name comp_desc <<< "${MON_DESCRIPTIONS[$i]}"

    COMP_MATCH=$(echo "$MON_PODS" | grep "$COMP" || true)
    if [ -z "$COMP_MATCH" ]; then
      fail "Monitoring component '$COMP' NOT found" "$comp_desc"
    elif echo "$COMP_MATCH" | grep -q "Running"; then
      pass "$COMP is Running"
    else
      STATUS=$(echo "$COMP_MATCH" | awk '{print $3}' | head -1)
      fail "$COMP is NOT Running (status: $STATUS)" \
"$comp_desc

DIAGNOSTIC:
  kubectl describe pod \$(kubectl get pods -n monitoring | grep $COMP | awk '{print \$1}' | head -1) -n monitoring
  kubectl logs \$(kubectl get pods -n monitoring | grep $COMP | awk '{print \$1}' | head -1) -n monitoring --tail=30"
    fi
  done

  # Check DaemonSets (promtail, node-exporter)
  MON_DS=$(kube get daemonsets -n monitoring --no-headers 2>/dev/null || echo "")
  if [ -n "$MON_DS" ]; then
    info "Monitoring DaemonSets:"
    echo "$MON_DS" | sed 's/^/          /'
  fi
fi

# =============================================================================
# CHECK 9 — Next.js Application
# =============================================================================
section "9 — Next.js Application"

NEXTJS_PODS=$(kube get pods -n nextjs-app --no-headers 2>/dev/null || echo "")
if [ -z "$NEXTJS_PODS" ]; then
  fail "No pods in 'nextjs-app' namespace" \
"COMPONENT: The Next.js application is the portfolio website — the main
user-facing workload. It runs as a Deployment in the nextjs-app namespace
with an HPA for autoscaling.

The deployment path: ArgoCD syncs the 'nextjs' Application from Git,
which renders the Helm chart and creates Deployment, Service, HPA,
IngressRoute, NetworkPolicy, ResourceQuota in the nextjs-app namespace.
Secrets are pre-seeded by deploy.py on first boot.

ROOT CAUSE:
  1. ArgoCD has not synced the nextjs Application
  2. The container image does not exist in ECR yet
  3. Kubernetes secrets (database table name, API URLs) were not created

WHERE TO LOOK:
  kubectl describe application nextjs -n argocd
  kubectl get events -n nextjs-app --sort-by='.lastTimestamp'"
else
  echo "$NEXTJS_PODS" | sed 's/^/          /'
  echo ""

  NEXTJS_RUNNING=$(echo "$NEXTJS_PODS" | grep -c "Running" || true)
  NEXTJS_TOTAL=$(echo "$NEXTJS_PODS" | wc -l | tr -d ' ')

  if [ "$NEXTJS_RUNNING" -eq "$NEXTJS_TOTAL" ] && [ "$NEXTJS_TOTAL" -gt 0 ]; then
    pass "All $NEXTJS_TOTAL Next.js pod(s) are Running"
  else
    NOT_RUNNING=$(echo "$NEXTJS_PODS" | grep -v "Running" || true)
    while IFS= read -r pod_line; do
      POD_STATUS=$(echo "$pod_line" | awk '{print $3}')
      POD_NAME_SHORT=$(echo "$pod_line" | awk '{print $1}')
      case "$POD_STATUS" in
        Pending)
          fail "Next.js pod '$POD_NAME_SHORT' is Pending" \
"The pod has been created but is not yet assigned to a node.

COMMON CAUSES:
  1. No node has the label 'role=application' (nodeSelector mismatch)
     → Check: kubectl get nodes --show-labels | grep application
  2. Insufficient CPU/memory on the application worker
     → Check: kubectl describe pod $POD_NAME_SHORT -n nextjs-app | grep -A 5 Events
  3. ResourceQuota exceeded in nextjs-app namespace
     → Check: kubectl describe resourcequota -n nextjs-app"
          ;;
        ImagePullBackOff|ErrImagePull)
          fail "Next.js pod '$POD_NAME_SHORT' — cannot pull container image" \
"Kubernetes cannot download the Next.js container image from ECR.

COMPONENT: The container image is the packaged Next.js application. It's
built by the CI pipeline and pushed to Amazon ECR (Elastic Container Registry).

CAUSES:
  1. Image does not exist in ECR (CI has not pushed it yet)
     → Check: aws ecr describe-images --repository-name <repo-name>
  2. The node's IAM instance profile lacks ECR pull permissions
     → The CDK stack should grant ecr:GetDownloadUrlForLayer, ecr:BatchGetImage
  3. Image tag is wrong (values.yaml references a tag that doesn't exist)

DIAGNOSTIC:
  kubectl describe pod $POD_NAME_SHORT -n nextjs-app | tail -20"
          ;;
        CrashLoopBackOff)
          fail "Next.js pod '$POD_NAME_SHORT' is CrashLoopBackOff" \
"The Next.js container starts but immediately crashes, and Kubernetes
keeps restarting it with exponential backoff.

COMMON CAUSES:
  1. Missing environment variables (database table, API host)
     → Check: kubectl describe pod $POD_NAME_SHORT -n nextjs-app | grep -A 20 Environment
  2. Application error at startup (build issue, missing dependencies)
     → Check: kubectl logs $POD_NAME_SHORT -n nextjs-app --previous
  3. Incorrect command/entrypoint in the Dockerfile
  4. Health probe failing too quickly (initialDelaySeconds too low)

THE --previous FLAG is critical: once a pod restarts, the old logs are
gone. Use --previous to see the logs from the crashed container."
          ;;
        *)
          fail "Next.js pod '$POD_NAME_SHORT' is in unexpected state: $POD_STATUS" \
"DIAGNOSTIC:
  kubectl describe pod $POD_NAME_SHORT -n nextjs-app
  kubectl logs $POD_NAME_SHORT -n nextjs-app --tail=50"
          ;;
      esac
    done <<< "$NOT_RUNNING"
  fi

  # Check deployment
  NEXTJS_DEPLOY=$(kube get deployment -n nextjs-app --no-headers 2>/dev/null || echo "")
  if [ -n "$NEXTJS_DEPLOY" ]; then
    info "Next.js Deployment:"
    echo "$NEXTJS_DEPLOY" | sed 's/^/          /'
  fi

  # Check HPA
  NEXTJS_HPA=$(kube get hpa -n nextjs-app --no-headers 2>/dev/null || echo "")
  if [ -n "$NEXTJS_HPA" ]; then
    pass "HPA (Horizontal Pod Autoscaler) exists for Next.js"
    echo "$NEXTJS_HPA" | sed 's/^/          /'
  else
    info "No HPA found for Next.js (may be disabled in development values)"
  fi

  # Check secrets
  NEXTJS_SECRETS=$(kube get secrets -n nextjs-app --no-headers 2>/dev/null | grep -v "default-token\|service-account" || echo "")
  if [ -n "$NEXTJS_SECRETS" ]; then
    SECRET_COUNT=$(echo "$NEXTJS_SECRETS" | wc -l | tr -d ' ')
    pass "Found $SECRET_COUNT secret(s) in nextjs-app namespace"
  else
    warn "No application secrets in nextjs-app namespace" \
"COMPONENT: Kubernetes Secrets store sensitive configuration that the Next.js
app needs at runtime (DynamoDB table name, API endpoints, etc.). They are
created by deploy.py which reads values from AWS SSM Parameter Store and
creates Kubernetes Secret objects before ArgoCD deploys the Helm chart.

If secrets are missing, the Next.js pods may start but return errors because
they can't read their configuration.

WHERE TO LOOK:
  kubectl get secrets -n nextjs-app
  # Check if deploy.py ran the secret creation step:
  kubectl get application nextjs -n argocd
  sudo grep -i 'secret\|ssm\|deploy.py' /var/log/cloud-init-output.log"
  fi
fi

# =============================================================================
# CHECK 10 — Services
# =============================================================================
section "10 — Services (Internal Load Balancers)"

ALL_SVC=$(kube get svc -A --no-headers 2>/dev/null)
echo "$ALL_SVC" | sed 's/^/          /'
echo ""

SVC_COUNT=$(echo "$ALL_SVC" | wc -l | tr -d ' ')
pass "Found $SVC_COUNT service(s) across all namespaces"

# =============================================================================
# CHECK 11 — Persistent Storage
# =============================================================================
section "11 — Persistent Storage"

PVS=$(kube get pv --no-headers 2>/dev/null || echo "")
PVCS=$(kube get pvc -A --no-headers 2>/dev/null || echo "")

if [ -n "$PVS" ]; then
  PV_COUNT=$(echo "$PVS" | wc -l | tr -d ' ')
  info "Persistent Volumes ($PV_COUNT):"
  echo "$PVS" | sed 's/^/          /'
else
  info "No Persistent Volumes found (may be expected for initial deployment)"
fi

if [ -n "$PVCS" ]; then
  echo ""
  PVC_COUNT=$(echo "$PVCS" | wc -l | tr -d ' ')
  BOUND_COUNT=$(echo "$PVCS" | grep -c "Bound" || true)
  info "Persistent Volume Claims ($PVC_COUNT):"
  echo "$PVCS" | sed 's/^/          /'

  if [ "$BOUND_COUNT" -eq "$PVC_COUNT" ]; then
    pass "All $PVC_COUNT PVCs are Bound"
  else
    UNBOUND=$(echo "$PVCS" | grep -v "Bound" || true)
    warn "Some PVCs are NOT Bound" \
"COMPONENT: A PersistentVolumeClaim (PVC) is a request for storage from a pod.
When a PVC is 'Bound', it means Kubernetes successfully allocated a physical
volume (PV). If a PVC is 'Pending', no matching PV could be found.

UNBOUND PVCs:
$(echo "$UNBOUND" | sed 's/^/  /')

COMMON CAUSES:
  1. No StorageClass matches the PVC request
  2. The local-path-provisioner is not running
  3. The EBS volume is not attached/mounted

DIAGNOSTIC:
  kubectl describe pvc <pvc-name> -n <namespace>
  kubectl get storageclass"
  fi
fi

# Check EBS mount
echo ""
if df -h /data &>/dev/null; then
  DISK_USAGE=$(df -h /data | tail -1)
  pass "EBS volume mounted at /data"
  echo "          $DISK_USAGE"
else
  warn "/data mount point not found (expected on control plane)" \
"COMPONENT: The EBS volume mounted at /data stores persistent data including
etcd backups and local-path-provisioner volumes. It's attached by the CDK
BaseStack and mounted by boot-k8s.sh.

DIAGNOSTIC:
  lsblk
  sudo fdisk -l"
fi

# =============================================================================
# CHECK 12 — Resource Usage
# =============================================================================
section "12 — Resource Usage"

if kube top nodes &>/dev/null; then
  pass "Metrics Server API is available"
  echo ""
  info "Node resource usage:"
  kube top nodes 2>/dev/null | sed 's/^/          /'
  echo ""
  info "Top 10 pods by CPU:"
  kube top pods -A --sort-by=cpu 2>/dev/null | head -11 | sed 's/^/          /'
else
  warn "Metrics API not available — 'kubectl top' will not work" \
"COMPONENT: The Metrics Server collects resource usage (CPU, memory) from
kubelets and makes it available via the Kubernetes Metrics API.

Without it:
  - 'kubectl top nodes' and 'kubectl top pods' commands fail
  - HPA (Horizontal Pod Autoscaler) cannot scale based on CPU/memory
  - Resource usage dashboards in Grafana may have gaps

The Metrics Server should be installed by boot-k8s.sh. Check:
  kubectl get deployment metrics-server -n kube-system"
fi

# Resource quotas
RQ=$(kube get resourcequotas -A --no-headers 2>/dev/null || echo "")
if [ -n "$RQ" ]; then
  info "Resource Quotas:"
  echo "$RQ" | sed 's/^/          /'
fi

# =============================================================================
# CHECK 13 — Network Policies
# =============================================================================
section "13 — Network Policies"

NETPOL=$(kube get networkpolicies -A --no-headers 2>/dev/null || echo "")
if [ -n "$NETPOL" ]; then
  NP_COUNT=$(echo "$NETPOL" | wc -l | tr -d ' ')
  pass "Found $NP_COUNT NetworkPolicy(s)"
  echo "$NETPOL" | sed 's/^/          /'
else
  info "No NetworkPolicies found (all pod-to-pod traffic is allowed by default)"
fi

# =============================================================================
# CHECK 14 — DNS Resolution
# =============================================================================
section "14 — DNS Resolution (CoreDNS)"

DNS_RESULT=$(kube run verify-dns --image=busybox:1.36 --rm -i --restart=Never --timeout=30s -- nslookup kubernetes.default 2>&1 || true)

if echo "$DNS_RESULT" | grep -q "Address"; then
  pass "DNS resolution working (kubernetes.default resolved)"
else
  fail "DNS resolution FAILED" \
"COMPONENT: CoreDNS provides internal DNS so pods can find services by name
(e.g., 'grafana.monitoring.svc.cluster.local' → ClusterIP). Without working
DNS, pods cannot discover other services.

THE TEST: We launched a temporary busybox pod and ran 'nslookup kubernetes.default'.
This should resolve to the Kubernetes API service's ClusterIP (usually 10.96.0.1).

OUTPUT:
$(echo "$DNS_RESULT" | sed 's/^/  /')

COMMON CAUSES:
  1. CoreDNS pods are not running:
     kubectl get pods -n kube-system | grep coredns
  2. Calico CNI is broken (pods can't communicate):
     kubectl get pods -n calico-system
  3. kube-proxy is not running (service ClusterIPs don't work):
     kubectl get pods -n kube-system | grep kube-proxy"
fi

# =============================================================================
# CHECK 15 — Pod Scheduling Validation
# =============================================================================
section "15 — Pod Scheduling (Pods on Correct Nodes)"

ALL_PODS_WIDE=$(kube get pods -A -o wide --no-headers 2>/dev/null || echo "")

if [ -n "$CP_NODE" ]; then
  # Check NextJS pods are on application worker
  NEXTJS_ON_CP=$(echo "$ALL_PODS_WIDE" | grep "nextjs-app" | grep "$CP_NODE" || true)
  if [ -n "$NEXTJS_ON_CP" ]; then
    warn "Next.js pods are running on the control plane node" \
"Next.js pods should run on the application worker (role=application),
not on the control plane. This could mean:
  1. The control-plane taint was removed
  2. The nodeSelector in the Helm chart is not working
  3. The application worker doesn't have the correct label

CHECK:
  kubectl get pods -n nextjs-app -o wide
  kubectl get nodes --show-labels | grep application"
  fi

  # Check monitoring pods are on monitoring worker
  MON_ON_CP=$(echo "$ALL_PODS_WIDE" | grep "^monitoring " | grep "$CP_NODE" | grep -v "node-exporter\|promtail" || true)
  if [ -n "$MON_ON_CP" ]; then
    warn "Monitoring pods are running on the control plane node" \
"Monitoring Deployments (Prometheus, Grafana, etc.) should run on the
monitoring worker (role=monitoring). DaemonSets like node-exporter and
promtail are expected on all nodes.

CHECK:
  kubectl get pods -n monitoring -o wide
  kubectl get nodes --show-labels | grep monitoring"
  fi
fi

if [ -n "$ALL_PODS_WIDE" ]; then
  pass "Pod scheduling check complete — see pod placement above"
fi

# =============================================================================
# CHECK 16 — End-to-End Connectivity
# =============================================================================
section "16 — End-to-End Connectivity"

if $SKIP_CONNECTIVITY; then
  skip "Connectivity tests skipped (--skip-connectivity flag)"
else
  # Test 1: Traefik local
  HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" --max-time 5 http://localhost 2>/dev/null || echo "000")
  if [ "$HTTP_CODE" = "200" ]; then
    pass "Traefik local test: HTTP $HTTP_CODE"
  elif [ "$HTTP_CODE" = "000" ]; then
    fail "Traefik not reachable on localhost:80 (connection refused)" \
"COMPONENT: Traefik runs as a DaemonSet with hostNetwork: true, which means
it binds directly to port 80 on every node. A curl to localhost:80 should
reach Traefik's HTTP entrypoint.

CAUSES:
  1. Traefik is not deployed yet (see Check 6 above)
  2. Traefik pod crashed — check: kubectl get pods -A | grep traefik
  3. Port 80 is blocked by iptables rules
  4. Another process is using port 80

DIAGNOSTIC:
  sudo ss -tlnp | grep ':80'"
  elif [ "$HTTP_CODE" = "404" ]; then
    warn "Traefik reachable but returned 404 (no matching route)" \
"Traefik is running but no IngressRoute matches the request.
This is expected if the Next.js app hasn't been deployed yet.
Once deploy.py runs, the IngressRoute will be created."
  else
    warn "Traefik returned HTTP $HTTP_CODE" \
"HTTP $HTTP_CODE may indicate the backend (Next.js) is not ready yet.
  502 = Bad Gateway — Traefik can't reach the backend service
  503 = Service Unavailable — the backend pods are starting up"
  fi

  # Test 2: Public IP
  PUBLIC_IP=$(curl -s --max-time 3 http://169.254.169.254/latest/meta-data/public-ipv4 2>/dev/null || echo "")
  if [ -n "$PUBLIC_IP" ]; then
    info "Public IP: $PUBLIC_IP"
    PUB_HTTP=$(curl -s -o /dev/null -w "%{http_code}" --max-time 5 "http://$PUBLIC_IP" 2>/dev/null || echo "000")
    if [ "$PUB_HTTP" = "200" ]; then
      pass "Public IP HTTP test: $PUB_HTTP"
    elif [ "$PUB_HTTP" = "000" ]; then
      warn "Cannot reach application via public IP ($PUBLIC_IP:80)" \
"This could mean:
  1. Security group does not allow inbound port 80 from self
  2. Network ACL blocks the traffic
  3. Traefik is not running"
    else
      info "Public IP returned HTTP $PUB_HTTP (may be normal during initial deploy)"
    fi
  else
    info "Could not retrieve public IP from IMDS"
  fi

  # Test 3: Certificate expiry
  CERT_CHECK=$(sudo kubeadm certs check-expiration 2>/dev/null || echo "NOT_AVAILABLE")
  if echo "$CERT_CHECK" | grep -q "EXPIRES"; then
    EXPIRED=$(echo "$CERT_CHECK" | grep "EXPIRED" || true)
    if [ -n "$EXPIRED" ]; then
      fail "Expired certificates detected" \
"COMPONENT: Kubernetes uses TLS certificates for API server authentication,
kubelet communication, and etcd encryption. Expired certificates cause
connection failures across the cluster.

FIX:
  sudo kubeadm certs renew all
  sudo systemctl restart kubelet"
    else
      pass "All certificates are valid"
    fi
  fi
fi

# =============================================================================
# CHECK 17 — Problem Pods Summary
# =============================================================================
section "17 — Problem Pods (non-Running, non-Completed)"

PROBLEM_PODS=$(kube get pods -A --no-headers 2>/dev/null | grep -v "Running\|Completed" || true)
if [ -z "$PROBLEM_PODS" ]; then
  pass "No problem pods — all pods are Running or Completed"
else
  PROBLEM_COUNT=$(echo "$PROBLEM_PODS" | wc -l | tr -d ' ')
  fail "$PROBLEM_COUNT pod(s) are in a non-healthy state" ""
  echo "$PROBLEM_PODS" | sed 's/^/          /'
  echo ""
  echo -e "  ${YLW}TIP: For each problem pod, run:${RST}"
  echo -e "    kubectl describe pod <POD_NAME> -n <NAMESPACE>"
  echo -e "    kubectl logs <POD_NAME> -n <NAMESPACE> --tail=50 --previous"
fi

# =============================================================================
# CHECK 18 — Recent Warning Events
# =============================================================================
section "18 — Recent Warning Events"

WARNING_EVENTS=$(kube get events -A --sort-by='.lastTimestamp' --field-selector type=Warning 2>/dev/null | tail -15 || true)
if [ -n "$WARNING_EVENTS" ] && ! echo "$WARNING_EVENTS" | grep -q "No resources found"; then
  warn "Recent warning events detected:"
  echo "$WARNING_EVENTS" | sed 's/^/          /'
else
  pass "No recent warning events"
fi

# =============================================================================
# FINAL SUMMARY
# =============================================================================
section "SUMMARY"

TOTAL=$((PASS + FAIL + WARN + SKIP))

echo ""
echo -e "  ${GRN}✅ Passed:  $PASS${RST}"
echo -e "  ${RED}❌ Failed:  $FAIL${RST}"
echo -e "  ${YLW}⚠️  Warnings: $WARN${RST}"
echo -e "  ${CYN}⏭️  Skipped:  $SKIP${RST}"
echo -e "  ─────────────────"
echo -e "  ${BLD}Total checks: $TOTAL${RST}"
echo ""

if [ "$FAIL" -gt 0 ]; then
  echo -e "${RED}${BLD}  ══════════════════════════════════════════════════════════════════════════${RST}"
  echo -e "${RED}${BLD}  FAILURES REQUIRING ATTENTION:${RST}"
  echo -e "${RED}${BLD}  ══════════════════════════════════════════════════════════════════════════${RST}"
  for f in "${FAILURES[@]}"; do
    echo -e "  ${RED}•${RST} $f"
  done
  echo ""
fi

if [ "$WARN" -gt 0 ]; then
  echo -e "${YLW}${BLD}  WARNINGS:${RST}"
  for w in "${WARNINGS[@]}"; do
    echo -e "  ${YLW}•${RST} $w"
  done
  echo ""
fi

if [ "$FAIL" -eq 0 ] && [ "$WARN" -eq 0 ]; then
  echo -e "  ${GRN}${BLD}🎉 All checks passed! The cluster is healthy and ready.${RST}"
elif [ "$FAIL" -eq 0 ]; then
  echo -e "  ${GRN}${BLD}✅ No critical failures. Review warnings above.${RST}"
else
  echo -e "  ${RED}${BLD}🔧 $FAIL failure(s) found. Review the detailed messages above.${RST}"
  echo -e "  ${BLD}Reference: docs/kubernetes/post-deployment-verification-guide.md${RST}"
fi

echo ""

# JSON output for automation
if $JSON_OUTPUT; then
  cat <<EOF
{
  "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "passed": $PASS,
  "failed": $FAIL,
  "warnings": $WARN,
  "skipped": $SKIP,
  "total": $TOTAL,
  "healthy": $([ "$FAIL" -eq 0 ] && echo "true" || echo "false")
}
EOF
fi

# Exit code: non-zero if any failures
exit $FAIL
